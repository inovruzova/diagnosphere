{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f9d0f7",
   "metadata": {},
   "source": [
    "# Understanding Bayes Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c7526",
   "metadata": {},
   "source": [
    "We have:\n",
    "\n",
    "- Nodes\n",
    "- Edges\n",
    "\n",
    "Bayes Nets encode the joint probability distribution of variables, allowing inference given evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8bb5f9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d23242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getsource\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74c44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c95e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_data = pd.read_csv(\"../data/cleaned_breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e8dd81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    int64  \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(2)\n",
      "memory usage: 142.4 KB\n"
     ]
    }
   ],
   "source": [
    "mental_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84574990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    mental_data,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=mental_data[\"diagnosis\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc8e4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = mental_data.columns\n",
    "for col in categorical_columns:\n",
    "    train_data[col] = train_data[col].astype(\"category\")\n",
    "    test_data[col] = test_data[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55bed83",
   "metadata": {},
   "source": [
    "# Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a05e60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(s, var, val):\n",
    "    \"\"\"Create a copy of dictionary `s` and add a new key-value pair where `var` is set to `val`. Return the updated copy.\"\"\"\n",
    "    return {**s, var: val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbDist:\n",
    "    \"\"\"\n",
    "    Represents a discrete probability distribution for a single random variable. \n",
    "    You can initialize it with a variable name and an optional frequency dictionary.\n",
    "    Probabilities are normalized automatically if frequencies are provided.\n",
    "\n",
    "    Example:\n",
    "    >>> P = ProbDist('Flip'); P['H'], P['T'] = 0.25, 0.75; P['H']\n",
    "    0.25\n",
    "    >>> P = ProbDist('X', {'lo': 125, 'med': 375, 'hi': 500})\n",
    "    >>> P['lo'], P['med'], P['hi']\n",
    "    (0.125, 0.375, 0.5)\n",
    "    \"\"\"\n",
    "    def __init__(self, varname='?', freqs=None):\n",
    "        \"\"\"\n",
    "        Initialize the distribution. If `freqs` is given, it must be a dictionary \n",
    "        with values as keys and their frequencies as values. The distribution is normalized.\n",
    "        \"\"\"\n",
    "        self.prob = {}\n",
    "        self.varname = varname\n",
    "        self.values = []\n",
    "        if freqs:\n",
    "            for (v, p) in freqs.items():\n",
    "                self[v] = p\n",
    "            self.normalize()\n",
    "\n",
    "    def __getitem__(self, val):\n",
    "        \"\"\"Retrieve the probability of `val` if it exists, otherwise return 0.\"\"\"\n",
    "        try:\n",
    "            return self.prob[val]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "    def __setitem__(self, val, p):\n",
    "        \"\"\"Assign probability `p` to the value `val`.\"\"\"\n",
    "        if val not in self.values:\n",
    "            self.values.append(val)\n",
    "        self.prob[val] = p\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"\n",
    "        Ensure that the probabilities of all values sum up to 1. \n",
    "        If the sum of values is 0, a ZeroDivisionError is raised.\n",
    "        \"\"\"\n",
    "        total = sum(self.prob.values())\n",
    "        if not np.isclose(total, 1.0):\n",
    "            for val in self.prob:\n",
    "                self.prob[val] /= total\n",
    "        return self\n",
    "\n",
    "    def show_approx(self, numfmt='{:.3g}'):\n",
    "        \"\"\"\n",
    "        Display the probabilities rounded to a specified format, sorted by their keys. \n",
    "        Useful for readability in doctests.\n",
    "        \"\"\"\n",
    "        return ', '.join([('{}: ' + numfmt).format(v, p)\n",
    "                          for (v, p) in sorted(self.prob.items())])\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return a string representation of the distribution.\"\"\"\n",
    "        return \"P({})\".format(self.varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93d67948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_sampling(probabilities):\n",
    "    \"\"\"\n",
    "    Perform random sampling based on the given probability distribution. \n",
    "    Returns an outcome based on the probabilities.\n",
    "    \"\"\"\n",
    "    total = sum(probabilities.values())\n",
    "    r = random.uniform(0, total)\n",
    "    cumulative = 0\n",
    "    for outcome, prob in probabilities.items():\n",
    "        cumulative += prob\n",
    "        if r <= cumulative:\n",
    "            return outcome\n",
    "    return None  # This should not occur if probabilities are normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7159ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassBayesNode:\n",
    "    \"\"\"\n",
    "    Represents a node in a Bayesian network for multi-class variables. \n",
    "    It contains the variable, its parents, and the conditional probability table (CPT).\n",
    "    \"\"\"\n",
    "    def __init__(self, X, parents, cpt):\n",
    "        \"\"\"\n",
    "        Initialize the node with:\n",
    "        - `X`: Variable name.\n",
    "        - `parents`: List of parent variable names.\n",
    "        - `cpt`: A dictionary representing the conditional probability table.\n",
    "        \"\"\"\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "        self.variable = X\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.children = []\n",
    "\n",
    "    def p(self, value, event):\n",
    "        \"\"\"\n",
    "        Compute the conditional probability of `X=value` given the parent values in `event`.\n",
    "        \"\"\"\n",
    "        parent_values = tuple(event.get(p, None) for p in self.parents)\n",
    "        probabilities = self.cpt.get(parent_values, {})\n",
    "        return probabilities.get(value, 0)  # Defaults to 0 if `value` is not found.\n",
    "\n",
    "    def sample(self, event):\n",
    "        \"\"\"\n",
    "        Sample a value for the variable given parent values in `event`. \n",
    "        Sampling is based on the conditional probability distribution.\n",
    "        \"\"\"\n",
    "        parent_values = tuple(event.get(p, None) for p in self.parents)\n",
    "        probabilities = self.cpt.get(parent_values, {})\n",
    "        return probability_sampling(probabilities)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return a string representation of the node.\"\"\"\n",
    "        return repr((self.variable, ' '.join(self.parents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b41a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet:\n",
    "    \"\"\"\n",
    "    Represents a Bayesian network consisting of nodes (variables) and their dependencies.\n",
    "    Supports multi-class nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_specs=None):\n",
    "        \"\"\"\n",
    "        Initialize the network. Nodes must be added in topological order \n",
    "        (parents must be added before their children).\n",
    "        \"\"\"\n",
    "        self.nodes = []\n",
    "        self.variables = []\n",
    "        node_specs = node_specs or []\n",
    "        for node_spec in node_specs:\n",
    "            self.add(node_spec)\n",
    "\n",
    "    def add(self, node_spec):\n",
    "        \"\"\"\n",
    "        Add a node to the network. Accepts either a pre-constructed node \n",
    "        or the specifications for a new node.\n",
    "        \"\"\"\n",
    "        if isinstance(node_spec, MultiClassBayesNode):\n",
    "            node = node_spec\n",
    "        else:\n",
    "            node = MultiClassBayesNode(*node_spec)\n",
    "\n",
    "        assert node.variable not in self.variables\n",
    "        assert all((parent in self.variables) for parent in node.parents)\n",
    "\n",
    "        self.nodes.append(node)\n",
    "        self.variables.append(node.variable)\n",
    "\n",
    "        # Register this node as a child for its parent nodes\n",
    "        for parent in node.parents:\n",
    "            self.variable_node(parent).children.append(node)\n",
    "\n",
    "    def variable_node(self, var):\n",
    "        \"\"\"Retrieve the node corresponding to the variable `var`.\"\"\"\n",
    "        for n in self.nodes:\n",
    "            if n.variable == var:\n",
    "                return n\n",
    "        raise Exception(f\"No such variable: {var}\")\n",
    "\n",
    "    def variable_values(self, var):\n",
    "        \"\"\"Retrieve the domain of `var` (default is `[True, False]`).\"\"\"\n",
    "        return [True, False]\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return a string representation of the network.\"\"\"\n",
    "        return f\"BayesNet({self.nodes!r})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01ebbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factor:\n",
    "    \"\"\"Represents a factor in a joint distribution.\"\"\"\n",
    "    def __init__(self, variables, cpt):\n",
    "        \"\"\"\n",
    "        Initialize the factor with:\n",
    "        - `variables`: List of variables involved in the factor.\n",
    "        - `cpt`: Conditional probability table.\n",
    "        \"\"\"\n",
    "        self.variables = variables\n",
    "        self.cpt = cpt\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"\n",
    "        Normalize the factor and return a `ProbDist` for the remaining variable.\n",
    "        This is only valid if the factor has one variable left.\n",
    "        \"\"\"\n",
    "        assert len(self.variables) == 1\n",
    "        return ProbDist(self.variables[0], {k: v for ((k,), v) in self.cpt.items()})\n",
    "\n",
    "    def p(self, e):\n",
    "        \"\"\"Retrieve the probability for the event `e` from the factor's CPT.\"\"\"\n",
    "        return self.cpt[event_values(e, self.variables)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d56a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_all(variables, e, bn):\n",
    "    \"\"\"\n",
    "    Calculate the sum of all entries in the joint probability distribution \n",
    "    for `variables` consistent with the evidence `e` in network `bn`.\n",
    "    \"\"\"\n",
    "    if not variables:\n",
    "        return 1.0\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    Ynode = bn.variable_node(Y)\n",
    "    if Y in e:\n",
    "        return Ynode.p(e[Y], e) * enumerate_all(rest, e, bn)\n",
    "    else:\n",
    "        return sum(Ynode.p(y, e) * enumerate_all(rest, extend(e, Y, y), bn)\n",
    "                   for y in bn.variable_values(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b1ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumeration_ask(X, e, bn):\n",
    "    \"\"\"\n",
    "    Compute the conditional probability distribution for the query variable `X` \n",
    "    given evidence `e` in the Bayesian network `bn`.\n",
    "    \"\"\"\n",
    "    assert X not in e, \"Query variable must not overlap with the evidence.\"\n",
    "    Q = ProbDist(X)\n",
    "    for xi in bn.variable_values(X):\n",
    "        Q[xi] = enumerate_all(bn.variables, extend(e, X, xi), bn)\n",
    "    return Q.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bc0e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_values(event, variables):\n",
    "    \"\"\"\n",
    "    Generate a tuple containing the values of the specified variables from the event.\n",
    "    \n",
    "    Examples:\n",
    "    >>> event_values({'A': 10, 'B': 9, 'C': 8}, ['C', 'A'])\n",
    "    (8, 10)\n",
    "    >>> event_values((1, 2), ['C', 'A'])\n",
    "    (1, 2)\n",
    "    \"\"\"\n",
    "    if isinstance(event, tuple) and len(event) == len(variables):\n",
    "        return event\n",
    "    else:\n",
    "        return tuple(event[var] for var in variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7389904",
   "metadata": {},
   "source": [
    "# Design the Network Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65308c",
   "metadata": {},
   "source": [
    "Find dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c62c2",
   "metadata": {},
   "source": [
    "# Estimate Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483d1bf",
   "metadata": {},
   "source": [
    "If a node is a root node, then estimate probability directly from the data. Estimate conditional probabilities based on parent for non-root nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "951ae0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cpt(data, target, parents, alpha=1):\n",
    "    \"\"\"\n",
    "    Compute CPT with Laplace smoothing.\n",
    "    \n",
    "    Args:\n",
    "        data: pandas DataFrame (training data)\n",
    "        target: str, target variable\n",
    "        parents: list of parent variable names\n",
    "        alpha: smoothing parameter (default=1)\n",
    "    \n",
    "    Returns:\n",
    "        cpt: dict { parent_values_tuple: { target_value: probability } }\n",
    "    \"\"\"\n",
    "    target_values = data[target].cat.categories\n",
    "\n",
    "    if not parents:\n",
    "        # Marginal distribution of target\n",
    "        counts = defaultdict(lambda: alpha)\n",
    "        for val in data[target]:\n",
    "            counts[val] += 1\n",
    "        total = sum(counts.values())\n",
    "        cpt = {(): {tv: counts[tv]/total for tv in counts}}\n",
    "        return cpt\n",
    "\n",
    "    # Determine possible parent combinations\n",
    "    from itertools import product\n",
    "    parent_values_list = [data[p].cat.categories for p in parents]\n",
    "    parent_combinations = list(product(*parent_values_list)) if parents else [()]\n",
    "\n",
    "    # Initialize counts with alpha\n",
    "    counts = {pc: defaultdict(lambda: alpha) for pc in parent_combinations}\n",
    "\n",
    "    # Count occurrences\n",
    "    for _, row in data.iterrows():\n",
    "        pv = tuple(row[p] for p in parents) if parents else ()\n",
    "        tv = row[target]\n",
    "        counts[pv][tv] += 1\n",
    "\n",
    "    # Compute probabilities\n",
    "    cpt = {}\n",
    "    for pc in parent_combinations:\n",
    "        total = sum(counts[pc].values())\n",
    "        cpt[pc] = {tv: (counts[pc][tv] / total) for tv in counts[pc]}\n",
    "        \n",
    "    return cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "628ab034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_cpts(train_data):\n",
    "    \"\"\"\n",
    "    Compute all CPTs and record the time taken.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Compute CPTs\n",
    "    cpt_diagnosis = compute_cpt(train_data, 'diagnosis', [])\n",
    "    cpt_concave_points = compute_cpt(train_data, 'concave points_mean', ['diagnosis'])\n",
    "    cpt_perimeter = compute_cpt(train_data, 'perimeter_mean', ['diagnosis'])\n",
    "    cpt_radius = compute_cpt(train_data, 'radius_mean', ['diagnosis'])\n",
    "    cpt_concavity = compute_cpt(train_data, 'concavity_mean', ['diagnosis', 'concave points_mean'])\n",
    "    cpt_texture = compute_cpt(train_data, 'texture_mean', ['diagnosis'])\n",
    "\n",
    "    cpt_area = compute_cpt(train_data, 'area_mean', ['perimeter_mean'])\n",
    "    cpt_compactness = compute_cpt(train_data, 'compactness_mean', ['concavity_mean'])\n",
    "    cpt_smoothness = compute_cpt(train_data, 'smoothness_mean', ['concavity_mean'])\n",
    "    cpt_symmetry = compute_cpt(train_data, 'symmetry_mean', ['compactness_mean'])\n",
    "    cpt_fractal = compute_cpt(train_data, 'fractal_dimension_mean', ['symmetry_mean'])\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time (CPT Computation): {training_time:.4f} seconds\")\n",
    "\n",
    "    return {\n",
    "        \"cpt_diagnosis\": cpt_diagnosis,\n",
    "        \"cpt_concave_points\": cpt_concave_points,\n",
    "        \"cpt_perimeter\": cpt_perimeter,\n",
    "        \"cpt_radius\": cpt_radius,\n",
    "        \"cpt_concavity\": cpt_concavity,\n",
    "        \"cpt_texture\": cpt_texture,\n",
    "        \"cpt_area\": cpt_area,\n",
    "        \"cpt_compactness\": cpt_compactness,\n",
    "        \"cpt_smoothness\": cpt_smoothness,\n",
    "        \"cpt_symmetry\": cpt_symmetry,\n",
    "        \"cpt_fractal\": cpt_fractal\n",
    "    }, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea9488",
   "metadata": {},
   "source": [
    "# Implement Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae3782a",
   "metadata": {},
   "source": [
    "Use the chain rule of probability to predict target given evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "652cf98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time (CPT Computation): 0.2046 seconds\n"
     ]
    }
   ],
   "source": [
    "cpts, training_time = compute_all_cpts(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c0a6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_node = MultiClassBayesNode(\"diagnosis\", [], cpts['cpt_diagnosis'])\n",
    "\n",
    "concave_points_node = MultiClassBayesNode(\n",
    "    \"concave points_mean\", [\"diagnosis\"], cpts['cpt_concave_points']\n",
    ")\n",
    "perimeter_node = MultiClassBayesNode(\"perimeter_mean\", [\"diagnosis\"], cpts['cpt_perimeter'])\n",
    "radius_node = MultiClassBayesNode(\"radius_mean\", [\"diagnosis\"], cpts['cpt_radius'])\n",
    "concavity_node = MultiClassBayesNode(\n",
    "    \"concavity_mean\", [\"diagnosis\", \"concave points_mean\"], cpts['cpt_concavity'])\n",
    "\n",
    "texture_node = MultiClassBayesNode(\"texture_mean\", [\"diagnosis\"], cpts['cpt_texture'])\n",
    "\n",
    "area_node = MultiClassBayesNode(\"area_mean\", [\"perimeter_mean\"], cpts['cpt_area'])\n",
    "compactness_node = MultiClassBayesNode(\"compactness_mean\", [\"concavity_mean\"], cpts['cpt_compactness'])\n",
    "smoothness_node = MultiClassBayesNode(\"smoothness_mean\", [\"concavity_mean\"], cpts['cpt_smoothness'])\n",
    "symmetry_node = MultiClassBayesNode(\"symmetry_mean\", [\"compactness_mean\"], cpts['cpt_symmetry'])\n",
    "fractal_node = MultiClassBayesNode(\"fractal_dimension_mean\", [\"symmetry_mean\"], cpts['cpt_fractal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd09a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_bn = BayesNet([\n",
    "    diagnosis_node,\n",
    "    concave_points_node,\n",
    "    perimeter_node,\n",
    "    radius_node,\n",
    "    concavity_node,\n",
    "    texture_node,\n",
    "    area_node,\n",
    "    compactness_node,\n",
    "    smoothness_node,\n",
    "    symmetry_node,\n",
    "    fractal_node\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1614601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesNet([('diagnosis', ''), ('concave points_mean', 'diagnosis'), ('perimeter_mean', 'diagnosis'), ('radius_mean', 'diagnosis'), ('concavity_mean', 'diagnosis concave points_mean'), ('texture_mean', 'diagnosis'), ('area_mean', 'perimeter_mean'), ('compactness_mean', 'concavity_mean'), ('smoothness_mean', 'concavity_mean'), ('symmetry_mean', 'compactness_mean'), ('fractal_dimension_mean', 'symmetry_mean')])\n"
     ]
    }
   ],
   "source": [
    "print(diagnosis_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4477f",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ff130e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bayes_net(bn, evidence, query_var):\n",
    "    \"\"\"\n",
    "    Predict the most likely value of a query variable given evidence using the Bayesian Network.\n",
    "    \n",
    "    Args:\n",
    "        bn: Bayesian network.\n",
    "        evidence: Dictionary of evidence variables and their values.\n",
    "        query_var: Variable to predict.\n",
    "    \n",
    "    Returns:\n",
    "        The most likely value of the query variable.\n",
    "    \"\"\"\n",
    "    result = enumeration_ask(query_var, evidence, bn)\n",
    "    return max(result.prob, key=lambda k: result.prob[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4de23a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bayes_net_with_time(bn, test_data, query_var):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Start Timing Predictions\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        evidence = {\n",
    "            \"Gender\": row[\"Gender\"],\n",
    "            \"Physical_Activity_Hours\": row[\"Physical_Activity_Hours\"],\n",
    "            \"Country\": row[\"Country\"],\n",
    "            \"Age\": row[\"Age\"],\n",
    "            \"Occupation\": row[\"Occupation\"],\n",
    "        }\n",
    "        prediction = predict_bayes_net(bn, evidence, query_var)\n",
    "        y_true.append(row[query_var])\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time\n",
    "\n",
    "    # Calculate Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"prediction_time\": prediction_time\n",
    "    }\n",
    "\n",
    "    print(f\"Prediction Time: {prediction_time:.4f} seconds\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3dafc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bayes_net(bn, test_data, query_var):\n",
    "    \"\"\"\n",
    "    Evaluate the Bayesian Network on a test dataset and compute various metrics.\n",
    "\n",
    "    Args:\n",
    "        bn: Bayesian Network (BayesNet instance).\n",
    "        test_data: Test dataset (pandas DataFrame).\n",
    "        query_var: The target variable to predict.\n",
    "\n",
    "    Returns:\n",
    "        metrics: A dictionary containing accuracy, and prints out confusion matrix\n",
    "                 and classification report (precision, recall, f1).\n",
    "    \"\"\"\n",
    "\n",
    "    # Start Timing Predictions\n",
    "    start_time = time.time()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        # Build evidence dictionary from test row\n",
    "        # Note: Adjust the evidence set according to what you want to condition on.\n",
    "        evidence = {\n",
    "            \"concave points_mean\": row[\"concave points_mean\"],\n",
    "            \"perimeter_mean\": row[\"perimeter_mean\"],\n",
    "            \"radius_mean\": row[\"radius_mean\"],\n",
    "            \"concavity_mean\": row[\"concavity_mean\"],\n",
    "            \"texture_mean\": row[\"texture_mean\"],\n",
    "            \"area_mean\": row[\"area_mean\"],\n",
    "            \"compactness_mean\": row[\"compactness_mean\"],\n",
    "            \"smoothness_mean\": row[\"smoothness_mean\"],\n",
    "            \"symmetry_mean\": row[\"symmetry_mean\"],\n",
    "            \"fractal_dimension_mean\": row[\"fractal_dimension_mean\"],\n",
    "        }\n",
    "\n",
    "        # Predict the target variable\n",
    "        prediction = predict_bayes_net(bn, evidence, query_var)\n",
    "\n",
    "        y_true.append(row[query_var])\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time    \n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    print(f\"Prediction Time: {prediction_time:.4f} seconds\")\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"prediction_time\": prediction_time\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "109c0492",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[134   9]\n",
      " [ 13  72]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92       143\n",
      "         1.0       0.89      0.85      0.87        85\n",
      "\n",
      "    accuracy                           0.90       228\n",
      "   macro avg       0.90      0.89      0.90       228\n",
      "weighted avg       0.90      0.90      0.90       228\n",
      "\n",
      "Prediction Time: 0.0971 seconds\n",
      "Accuracy: 0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_bayes_net(diagnosis_bn, test_data, \"diagnosis\")\n",
    "print(\"Accuracy:\", metrics[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bfcb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpts_to_json(cpts):\n",
    "    serializable_cpts = {}\n",
    "    for var, cpt in cpts.items():\n",
    "        serializable_cpts[var] = {\n",
    "            str(parent_comb): {str(k): v for k, v in target_probs.items()}\n",
    "            for parent_comb, target_probs in cpt.items()\n",
    "        }\n",
    "    return serializable_cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46a581bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPTs saved successfully to cancer_cpts.json!\n"
     ]
    }
   ],
   "source": [
    "# Save the CPTs to a JSON file\n",
    "cpt_json = cpts_to_json(cpts)\n",
    "with open(\"cancer_cpts.json\", \"w\") as f:\n",
    "    json.dump(cpt_json, f, indent=4)\n",
    "print(\"CPTs saved successfully to cancer_cpts.json!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
