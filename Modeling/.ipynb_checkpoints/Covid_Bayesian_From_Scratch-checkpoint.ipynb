{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f9d0f7",
   "metadata": {},
   "source": [
    "# Understanding Bayes Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c7526",
   "metadata": {},
   "source": [
    "We have:\n",
    "\n",
    "- Nodes: Variables\n",
    "- Edges: Dependencies between variables\n",
    "\n",
    "Bayes Nets encode the joint probability distribution of variables, allowing inference given evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8bb5f9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c3d23242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getsource\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b74c44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d2c95e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/covid_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "214b816c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USMER', 'MEDICAL_UNIT', 'SEX', 'PATIENT_TYPE', 'DATE_DIED', 'INTUBED',\n",
       "       'PNEUMONIA', 'AGE', 'PREGNANT', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR',\n",
       "       'HIPERTENSION', 'OTHER_DISEASE', 'CARDIOVASCULAR', 'OBESITY',\n",
       "       'RENAL_CHRONIC', 'TOBACCO', 'CLASIFFICATION_FINAL', 'ICU', 'AGE_GROUP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "84574990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"CLASIFFICATION_FINAL\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "dc8e4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['AGE_GROUP', 'PNEUMONIA', 'ICU', 'CLASIFFICATION_FINAL', 'SEX', 'OBESITY', 'DIABETES']\n",
    "for col in categorical_columns:\n",
    "    train_data[col] = train_data[col].astype(\"category\")\n",
    "    test_data[col] = test_data[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "10333244",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    train_data[col] = train_data[col].cat.remove_unused_categories()\n",
    "    test_data[col] = test_data[col].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55bed83",
   "metadata": {},
   "source": [
    "# Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a05e60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(s, var, val):\n",
    "    \"\"\"Copy dict s and extend it by setting var to val; return copy.\"\"\"\n",
    "    return {**s, var: val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e0462f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_with(event, evidence):\n",
    "    \"\"\"Is event consistent with the given evidence?\"\"\"\n",
    "    return all(evidence.get(k, v) == v\n",
    "               for k, v in event.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2fc77e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(p):\n",
    "    \"\"\"Return true with probability p.\"\"\"\n",
    "    return p > random.uniform(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1a3fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbDist:\n",
    "    \"\"\"A discrete probability distribution. You name the random variable\n",
    "    in the constructor, then assign and query probability of values.\n",
    "    >>> P = ProbDist('Flip'); P['H'], P['T'] = 0.25, 0.75; P['H']\n",
    "    0.25\n",
    "    >>> P = ProbDist('X', {'lo': 125, 'med': 375, 'hi': 500})\n",
    "    >>> P['lo'], P['med'], P['hi']\n",
    "    (0.125, 0.375, 0.5)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, varname='?', freqs=None):\n",
    "        \"\"\"If freqs is given, it is a dictionary of values - frequency pairs,\n",
    "        then ProbDist is normalized.\"\"\"\n",
    "        self.prob = {}\n",
    "        self.varname = varname\n",
    "        self.values = []\n",
    "        if freqs:\n",
    "            for (v, p) in freqs.items():\n",
    "                self[v] = p\n",
    "            self.normalize()\n",
    "\n",
    "    def __getitem__(self, val):\n",
    "        \"\"\"Given a value, return P(value).\"\"\"\n",
    "        try:\n",
    "            return self.prob[val]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "    def __setitem__(self, val, p):\n",
    "        \"\"\"Set P(val) = p.\"\"\"\n",
    "        if val not in self.values:\n",
    "            self.values.append(val)\n",
    "        self.prob[val] = p\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"Make sure the probabilities of all values sum to 1.\n",
    "        Returns the normalized distribution.\n",
    "        Raises a ZeroDivisionError if the sum of the values is 0.\"\"\" \n",
    "        total = sum(self.prob.values())\n",
    "        if not np.isclose(total, 1.0):\n",
    "            for val in self.prob:\n",
    "                self.prob[val] /= total\n",
    "        return self\n",
    "\n",
    "    def show_approx(self, numfmt='{:.3g}'):\n",
    "        \"\"\"Show the probabilities rounded and sorted by key, for the\n",
    "        sake of portable doctests.\"\"\"\n",
    "        return ', '.join([('{}: ' + numfmt).format(v, p)\n",
    "                          for (v, p) in sorted(self.prob.items())])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({})\".format(self.varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "37f7de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointProbDist(ProbDist):\n",
    "    \"\"\"A discrete probability distribute over a set of variables.\n",
    "    >>> P = JointProbDist(['X', 'Y']); P[1, 1] = 0.25\n",
    "    >>> P[1, 1]\n",
    "    0.25\n",
    "    >>> P[dict(X=0, Y=1)] = 0.5\n",
    "    >>> P[dict(X=0, Y=1)]\n",
    "    0.5\"\"\"\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        self.prob = {}\n",
    "        self.variables = variables\n",
    "        self.vals = defaultdict(list)\n",
    "\n",
    "    def __getitem__(self, values):\n",
    "        \"\"\"Given a tuple or dict of values, return P(values).\"\"\"\n",
    "        values = event_values(values, self.variables)\n",
    "        return ProbDist.__getitem__(self, values)\n",
    "\n",
    "    def __setitem__(self, values, p):\n",
    "        \"\"\"Set P(values) = p.  Values can be a tuple or a dict; it must\n",
    "        have a value for each of the variables in the joint. Also keep track\n",
    "        of the values we have seen so far for each variable.\"\"\"\n",
    "        values = event_values(values, self.variables)\n",
    "        self.prob[values] = p\n",
    "        for var, val in zip(self.variables, values):\n",
    "            if val not in self.vals[var]:\n",
    "                self.vals[var].append(val)\n",
    "\n",
    "    def values(self, var):\n",
    "        \"\"\"Return the set of possible values for a variable.\"\"\"\n",
    "        return self.vals[var]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({})\".format(self.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e82e018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNode:\n",
    "    \"\"\"A conditional probability distribution for a boolean variable,\n",
    "    P(X | parents). Part of a BayesNet.\"\"\"\n",
    "\n",
    "    def __init__(self, X, parents, cpt):\n",
    "        \"\"\"X is a variable name, and parents a sequence of variable\n",
    "        names or a space-separated string.  cpt, the conditional\n",
    "        probability table, takes one of these forms:\n",
    "\n",
    "        * A number, the unconditional probability P(X=true). You can\n",
    "          use this form when there are no parents.\n",
    "\n",
    "        * A dict {v: p, ...}, the conditional probability distribution\n",
    "          P(X=true | parent=v) = p. When there's just one parent.\n",
    "\n",
    "        * A dict {(v1, v2, ...): p, ...}, the distribution P(X=true |\n",
    "          parent1=v1, parent2=v2, ...) = p. Each key must have as many\n",
    "          values as there are parents. You can use this form always;\n",
    "          the first two are just conveniences.\n",
    "\n",
    "        In all cases the probability of X being false is left implicit,\n",
    "        since it follows from P(X=true).\n",
    "\n",
    "        >>> X = BayesNode('X', '', 0.2)\n",
    "        >>> Y = BayesNode('Y', 'P', {T: 0.2, F: 0.7})\n",
    "        >>> Z = BayesNode('Z', 'P Q',\n",
    "        ...    {(T, T): 0.2, (T, F): 0.3, (F, T): 0.5, (F, F): 0.7})\n",
    "        \"\"\"\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "\n",
    "        # We store the table always in the third form above.\n",
    "        if isinstance(cpt, (float, int)):  # no parents, 0-tuple\n",
    "            cpt = {(): cpt}\n",
    "        elif isinstance(cpt, dict):\n",
    "            # one parent, 1-tuple\n",
    "            if cpt and isinstance(list(cpt.keys())[0], bool):\n",
    "                cpt = {(v,): p for v, p in cpt.items()}\n",
    "\n",
    "        assert isinstance(cpt, dict)\n",
    "        for vs, p in cpt.items():\n",
    "            assert isinstance(vs, tuple) and len(vs) == len(parents)\n",
    "            assert all(isinstance(v, bool) for v in vs)\n",
    "            assert 0 <= p <= 1\n",
    "\n",
    "        self.variable = X\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.children = []\n",
    "\n",
    "    def p(self, value, event):\n",
    "        \"\"\"Return the conditional probability\n",
    "        P(X=value | parents=parent_values), where parent_values\n",
    "        are the values of parents in event. (event must assign each\n",
    "        parent a value.)\n",
    "        >>> bn = BayesNode('X', 'Burglary', {T: 0.2, F: 0.625})\n",
    "        >>> bn.p(False, {'Burglary': False, 'Earthquake': True})\n",
    "        0.375\"\"\"\n",
    "        assert isinstance(value, bool)\n",
    "        ptrue = self.cpt[event_values(event, self.parents)]\n",
    "        return ptrue if value else 1 - ptrue\n",
    "\n",
    "    def sample(self, event):\n",
    "        \"\"\"Sample from the distribution for this variable conditioned\n",
    "        on event's values for parent_variables. That is, return True/False\n",
    "        at random according with the conditional probability given the\n",
    "        parents.\"\"\"\n",
    "        return probability(self.p(True, event))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr((self.variable, ' '.join(self.parents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "93d67948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_sampling(probabilities):\n",
    "    \"\"\"Randomly sample an outcome from a probability distribution.\"\"\"\n",
    "    total = sum(probabilities.values())\n",
    "    r = random.uniform(0, total)\n",
    "    cumulative = 0\n",
    "    for outcome, prob in probabilities.items():\n",
    "        cumulative += prob\n",
    "        if r <= cumulative:\n",
    "            return outcome\n",
    "    return None  # Should not reach here if probabilities are normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7159ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassBayesNode:\n",
    "    \"\"\"A Bayesian node for multi-class variables.\"\"\"\n",
    "    def __init__(self, X, parents, cpt):\n",
    "        \"\"\"\n",
    "        X: Name of the variable.\n",
    "        parents: List of parent variable names.\n",
    "        cpt: Conditional probability table, mapping tuples of parent values to\n",
    "             dictionaries of target probabilities.\n",
    "        \"\"\"\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "        self.variable = X\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.children = []\n",
    "\n",
    "    def p(self, value, event):\n",
    "        \"\"\"Return the conditional probability P(X=value | parents=parent_values).\"\"\"\n",
    "        parent_values = tuple(event.get(p, None) for p in self.parents)\n",
    "        probabilities = self.cpt.get(parent_values, {})\n",
    "        return probabilities.get(value, 0)  # Default to 0 if value not found\n",
    "\n",
    "    def sample(self, event):\n",
    "        \"\"\"Sample from the distribution for this variable given parent values.\"\"\"\n",
    "        parent_values = tuple(event.get(p, None) for p in self.parents)\n",
    "        probabilities = self.cpt.get(parent_values, {})\n",
    "        return probability_sampling(probabilities)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr((self.variable, ' '.join(self.parents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "a1b41a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet:\n",
    "    \"\"\"Bayesian network containing only boolean-variable or multi-class nodes.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_specs=None):\n",
    "        \"\"\"Nodes must be ordered with parents before children.\"\"\"\n",
    "        self.nodes = []\n",
    "        self.variables = []\n",
    "        node_specs = node_specs or []\n",
    "        for node_spec in node_specs:\n",
    "            self.add(node_spec)\n",
    "\n",
    "    def add(self, node_spec):\n",
    "        \"\"\"Add a node to the net. Supports both pre-constructed nodes and node specs.\"\"\"\n",
    "        if isinstance(node_spec, (BayesNode, MultiClassBayesNode)):\n",
    "            # If already a node, add it directly\n",
    "            node = node_spec\n",
    "        else:\n",
    "            # Otherwise, initialize a new node\n",
    "            node = BayesNode(*node_spec)\n",
    "\n",
    "        assert node.variable not in self.variables\n",
    "        assert all((parent in self.variables) for parent in node.parents)\n",
    "\n",
    "        self.nodes.append(node)\n",
    "        self.variables.append(node.variable)\n",
    "\n",
    "        # Register children for the parent nodes\n",
    "        for parent in node.parents:\n",
    "            self.variable_node(parent).children.append(node)\n",
    "\n",
    "    def variable_node(self, var):\n",
    "        \"\"\"Return the node for the variable named var.\"\"\"\n",
    "        for n in self.nodes:\n",
    "            if n.variable == var:\n",
    "                return n\n",
    "        raise Exception(f\"No such variable: {var}\")\n",
    "\n",
    "    def variable_values(self, var):\n",
    "        \"\"\"Return the domain of var.\"\"\"\n",
    "        return [True, False]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BayesNet({self.nodes!r})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "cacc07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_factor(var, e, bn):\n",
    "    \"\"\"Return the factor for var in bn's joint distribution given e.\n",
    "    That is, bn's full joint distribution, projected to accord with e,\n",
    "    is the pointwise product of these factors for bn's variables.\"\"\"\n",
    "    node = bn.variable_node(var)\n",
    "    variables = [X for X in [var] + node.parents if X not in e]\n",
    "    cpt = {event_values(e1, variables): node.p(e1[var], e1)\n",
    "           for e1 in all_events(variables, bn, e)}\n",
    "    return Factor(variables, cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c01ebbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factor:\n",
    "    \"\"\"A factor in a joint distribution.\"\"\"\n",
    "\n",
    "    def __init__(self, variables, cpt):\n",
    "        self.variables = variables\n",
    "        self.cpt = cpt\n",
    "\n",
    "    def pointwise_product(self, other, bn):\n",
    "        \"\"\"Multiply two factors, combining their variables.\"\"\"\n",
    "        variables = list(set(self.variables) | set(other.variables))\n",
    "        cpt = {event_values(e, variables): self.p(e) * other.p(e) for e in all_events(variables, bn, {})}\n",
    "        return Factor(variables, cpt)\n",
    "\n",
    "    def sum_out(self, var, bn):\n",
    "        \"\"\"Make a factor eliminating var by summing over its values.\"\"\"\n",
    "        variables = [X for X in self.variables if X != var]\n",
    "        cpt = {event_values(e, variables): sum(self.p(extend(e, var, val)) for val in bn.variable_values(var))\n",
    "               for e in all_events(variables, bn, {})}\n",
    "        return Factor(variables, cpt)\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"Return my probabilities; must be down to one variable.\"\"\"\n",
    "        assert len(self.variables) == 1\n",
    "        return ProbDist(self.variables[0], {k: v for ((k,), v) in self.cpt.items()})\n",
    "\n",
    "    def p(self, e):\n",
    "        \"\"\"Look up my value tabulated for e.\"\"\"\n",
    "        return self.cpt[event_values(e, self.variables)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3d56a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_all(variables, e, bn):\n",
    "    \"\"\"Return the sum of those entries in P(variables | e{others})\n",
    "    consistent with e, where P is the joint distribution represented\n",
    "    by bn, and e{others} means e restricted to bn's other variables\n",
    "    (the ones other than variables). Parents must precede children in variables.\"\"\"\n",
    "    if not variables:\n",
    "        return 1.0\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    Ynode = bn.variable_node(Y)\n",
    "    if Y in e:\n",
    "        return Ynode.p(e[Y], e) * enumerate_all(rest, e, bn)\n",
    "    else:\n",
    "        return sum(Ynode.p(y, e) * enumerate_all(rest, extend(e, Y, y), bn)\n",
    "                   for y in bn.variable_values(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "29b1ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumeration_ask(X, e, bn):\n",
    "    \"\"\"Return the conditional probability distribution of variable X\n",
    "    given evidence e, from BayesNet bn. [Figure 14.9]\n",
    "    >>> enumeration_ask('Burglary', dict(JohnCalls=T, MaryCalls=T), burglary\n",
    "    ...  ).show_approx()\n",
    "    'False: 0.716, True: 0.284'\"\"\"\n",
    "    assert X not in e, \"Query variable must be distinct from evidence\"\n",
    "    Q = ProbDist(X)\n",
    "    for xi in bn.variable_values(X):\n",
    "        Q[xi] = enumerate_all(bn.variables, extend(e, X, xi), bn)\n",
    "    return Q.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e2a85ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimination_ask(X, e, bn):\n",
    "    \"\"\"Compute bn's P(X|e) by variable elimination. [Figure 14.11]\n",
    "    >>> elimination_ask('Burglary', dict(JohnCalls=T, MaryCalls=T), burglary\n",
    "    ...  ).show_approx()\n",
    "    'False: 0.716, True: 0.284'\"\"\"\n",
    "    assert X not in e, \"Query variable must be distinct from evidence\"\n",
    "    factors = []\n",
    "    for var in reversed(bn.variables):\n",
    "        factors.append(make_factor(var, e, bn))\n",
    "        if is_hidden(var, X, e):\n",
    "            factors = sum_out(var, factors, bn)\n",
    "    return pointwise_product(factors, bn).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7df22d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_sample(bn):\n",
    "    \"\"\"Randomly sample from bn's full joint distribution. The result\n",
    "    is a {variable: value} dict. [Figure 14.13]\"\"\"\n",
    "    event = {}\n",
    "    for node in bn.nodes:\n",
    "        event[node.variable] = node.sample(event)\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0b4189e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampling(X, e, bn, N=10000):\n",
    "    \"\"\"Estimate the probability distribution of variable X given\n",
    "    evidence e in BayesNet bn, using N samples.  [Figure 14.14]\n",
    "    Raises a ZeroDivisionError if all the N samples are rejected,\n",
    "    i.e., inconsistent with e.\n",
    "    >>> random.seed(47)\n",
    "    >>> rejection_sampling('Burglary', dict(JohnCalls=T, MaryCalls=T),\n",
    "    ...   burglary, 10000).show_approx()\n",
    "    'False: 0.7, True: 0.3'\n",
    "    \"\"\"\n",
    "    counts = {x: 0 for x in bn.variable_values(X)}  # bold N in [Figure 14.14]\n",
    "    for j in range(N):\n",
    "        sample = prior_sample(bn)  # boldface x in [Figure 14.14]\n",
    "        if consistent_with(sample, e):\n",
    "            counts[sample[X]] += 1\n",
    "    return ProbDist(X, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "60855c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_weighting(X, e, bn, N=10000):\n",
    "    \"\"\"Estimate the probability distribution of variable X given\n",
    "    evidence e in BayesNet bn.  [Figure 14.15]\n",
    "    >>> random.seed(1017)\n",
    "    >>> likelihood_weighting('Burglary', dict(JohnCalls=T, MaryCalls=T),\n",
    "    ...   burglary, 10000).show_approx()\n",
    "    'False: 0.702, True: 0.298'\n",
    "    \"\"\"\n",
    "    W = {x: 0 for x in bn.variable_values(X)}\n",
    "    for j in range(N):\n",
    "        sample, weight = weighted_sample(bn, e)  # boldface x, w in [Figure 14.15]\n",
    "        W[sample[X]] += weight\n",
    "    return ProbDist(X, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "c441e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_ask(X, e, bn, N=1000):\n",
    "    \"\"\"[Figure 14.16]\"\"\"\n",
    "    assert X not in e, \"Query variable must be distinct from evidence\"\n",
    "    counts = {x: 0 for x in bn.variable_values(X)}  # bold N in [Figure 14.16]\n",
    "    Z = [var for var in bn.variables if var not in e]\n",
    "    state = dict(e)  # boldface x in [Figure 14.16]\n",
    "    for Zi in Z:\n",
    "        state[Zi] = random.choice(bn.variable_values(Zi))\n",
    "    for j in range(N):\n",
    "        for Zi in Z:\n",
    "            state[Zi] = markov_blanket_sample(Zi, state, bn)\n",
    "            counts[state[X]] += 1\n",
    "    return ProbDist(X, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4759d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_product(self, other, bn):\n",
    "        \"\"\"Multiply two factors, combining their variables.\"\"\"\n",
    "        variables = list(set(self.variables) | set(other.variables))\n",
    "        cpt = {event_values(e, variables): self.p(e) * other.p(e)\n",
    "               for e in all_events(variables, bn, {})}\n",
    "        return Factor(variables, cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b6c8285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_out(self, var, bn):\n",
    "        \"\"\"Make a factor eliminating var by summing over its values.\"\"\"\n",
    "        variables = [X for X in self.variables if X != var]\n",
    "        cpt = {event_values(e, variables): sum(self.p(extend(e, var, val))\n",
    "                                               for val in bn.variable_values(var))\n",
    "               for e in all_events(variables, bn, {})}\n",
    "        return Factor(variables, cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9bc0e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_values(event, variables):\n",
    "    \"\"\"Return a tuple of the values of variables in event.\n",
    "    >>> event_values ({'A': 10, 'B': 9, 'C': 8}, ['C', 'A'])\n",
    "    (8, 10)\n",
    "    >>> event_values ((1, 2), ['C', 'A'])\n",
    "    (1, 2)\n",
    "    \"\"\"\n",
    "    if isinstance(event, tuple) and len(event) == len(variables):\n",
    "        return event\n",
    "    else:\n",
    "        return tuple([event[var] for var in variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7389904",
   "metadata": {},
   "source": [
    "# Design the Network Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65308c",
   "metadata": {},
   "source": [
    "Find dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c62c2",
   "metadata": {},
   "source": [
    "# Estimate Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483d1bf",
   "metadata": {},
   "source": [
    "If a node is a root node, then estimate probability directly from the data. Estimate conditional probabilities based on parent for non-root nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "951ae0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cpt(data, target, parents, alpha=1):\n",
    "    \"\"\"\n",
    "    Compute CPT with Laplace smoothing.\n",
    "    \n",
    "    Args:\n",
    "        \n",
    "        data: pandas DataFrame (training data)\n",
    "        target: str, target variable\n",
    "        parents: list of parent variable names\n",
    "        alpha: smoothing parameter (default=1)\n",
    "    \n",
    "    Returns:\n",
    "        cpt: dict { parent_values_tuple: { target_value: probability } }\n",
    "    \"\"\"\n",
    "    target_values = data[target].cat.categories\n",
    "    \n",
    "    print(\"TARGET VALUES: \", target_values)\n",
    "\n",
    "    if not parents:\n",
    "        # Marginal distribution of target\n",
    "        counts = defaultdict(lambda: alpha)\n",
    "        for val in data[target]:\n",
    "            counts[val] += 1\n",
    "        total = sum(counts.values())\n",
    "        cpt = {(): {tv: counts[tv]/total for tv in counts}}\n",
    "        return cpt\n",
    "\n",
    "    # Determine possible parent combinations\n",
    "    from itertools import product\n",
    "    parent_values_list = [data[p].cat.categories for p in parents]\n",
    "    print(\"PARENT VALUES LIST\", parent_values_list)\n",
    "    print(\"PARENTS\", parents)\n",
    "    print(\"data DIABATES CATEOGORIES\", data['DIABETES'].cat.categories)\n",
    "    parent_combinations = list(product(*parent_values_list)) if parents else [()]\n",
    "\n",
    "    # Initialize counts with alpha\n",
    "    counts = {pc: defaultdict(lambda: alpha) for pc in parent_combinations}\n",
    "\n",
    "    # Count occurrences\n",
    "    for _, row in data.iterrows():\n",
    "        pv = tuple(row[p] for p in parents) if parents else ()\n",
    "        tv = row[target]\n",
    "        counts[pv][tv] += 1\n",
    "\n",
    "    # Compute probabilities\n",
    "    cpt = {}\n",
    "    for pc in parent_combinations:\n",
    "        total = sum(counts[pc].values())\n",
    "        cpt[pc] = {tv: (counts[pc][tv] / total) for tv in counts[pc]}\n",
    "        \n",
    "    return cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "cca9e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_cpts(train_data):\n",
    "    \"\"\"\n",
    "    Compute all CPTs and record the time taken.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Compute CPTs\n",
    "    cpt_icu = compute_cpt(train_data, 'ICU', ['PNEUMONIA'])\n",
    "    cpt_pneumonia = compute_cpt(train_data, 'PNEUMONIA', ['AGE_GROUP'])\n",
    "    cpt_age_group = compute_cpt(train_data, 'AGE_GROUP', [])\n",
    "    cpt_sex_group = compute_cpt(train_data, 'SEX', [])\n",
    "    cpt_obesity_group = compute_cpt(train_data, 'OBESITY', [])\n",
    "    cpt_diabetes_group = compute_cpt(train_data, 'DIABETES', [])\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time (CPT Computation): {training_time:.4f} seconds\")\n",
    "\n",
    "    return {\n",
    "        \"cpt_classification\": cpt_classification,\n",
    "        \"cpt_icu\": cpt_icu,\n",
    "        \"cpt_pneumonia\": cpt_pneumonia,\n",
    "        \"cpt_age_group\": cpt_age_group,\n",
    "        \"cpt_sex_group\": cpt_sex_group,\n",
    "        \"cpt_obesity_group\": cpt_obesity_group,\n",
    "        \"cpt_diabetes_group\": cpt_diabetes_group\n",
    "    }, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "2ca59382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET VALUES:  Index([1, 2], dtype='int64')\n",
      "PARENT VALUES LIST [Index([1, 2], dtype='int64')]\n",
      "PARENTS ['PNEUMONIA']\n",
      "data DIABATES CATEOGORIES Index([1, 2], dtype='int64')\n",
      "TARGET VALUES:  Index([1, 2], dtype='int64')\n",
      "PARENT VALUES LIST [Index(['20-40', '40-60', '60-80', '80+', '<20'], dtype='object')]\n",
      "PARENTS ['AGE_GROUP']\n",
      "data DIABATES CATEOGORIES Index([1, 2], dtype='int64')\n",
      "TARGET VALUES:  Index(['20-40', '40-60', '60-80', '80+', '<20'], dtype='object')\n",
      "TARGET VALUES:  Index([1, 2], dtype='int64')\n",
      "TARGET VALUES:  Index([1, 2], dtype='int64')\n",
      "TARGET VALUES:  Index([1, 2], dtype='int64')\n",
      "Training Time (CPT Computation): 68.8942 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure Training Time\n",
    "cpts, training_time = compute_all_cpts(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea9488",
   "metadata": {},
   "source": [
    "# Implement Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae3782a",
   "metadata": {},
   "source": [
    "Use the chain rule of probability to predict target given evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "47de2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_node = MultiClassBayesNode(\"CLASIFFICATION_FINAL\", ['SEX', 'OBESITY', 'DIABETES', 'ICU'], cpts[\"cpt_classification\"])\n",
    "pneumonia_node = MultiClassBayesNode(\"PNEUMONIA\", [\"AGE_GROUP\"], cpts[\"cpt_pneumonia\"])\n",
    "icu_node = MultiClassBayesNode(\"ICU\", [\"PNEUMONIA\"], cpts[\"cpt_icu\"])\n",
    "age_node = MultiClassBayesNode(\"AGE_GROUP\", [], cpts[\"cpt_age_group\"])\n",
    "obesity_node = MultiClassBayesNode(\"OBESITY\", [], cpts[\"cpt_obesity_group\"])\n",
    "sex_node = MultiClassBayesNode(\"SEX\", [], cpts[\"cpt_sex_group\"])\n",
    "diabetes_node = MultiClassBayesNode(\"DIABETES\", [], cpts[\"cpt_diabetes_group\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c0c480fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_final = BayesNet([\n",
    "    age_node,\n",
    "    sex_node,\n",
    "    obesity_node,\n",
    "    diabetes_node,\n",
    "    pneumonia_node,\n",
    "    icu_node,\n",
    "    classification_node\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4477f",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0ff130e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bayes_net(bn, evidence, query_var):\n",
    "    \"\"\"\n",
    "    Predict the most likely value of a query variable given evidence using the Bayesian Network.\n",
    "    \n",
    "    Args:\n",
    "        bn: Bayesian network.\n",
    "        evidence: Dictionary of evidence variables and their values.\n",
    "        query_var: Variable to predict.\n",
    "    \n",
    "    Returns:\n",
    "        The most likely value of the query variable.\n",
    "    \"\"\"\n",
    "    result = enumeration_ask(query_var, evidence, bn)\n",
    "    return max(result.prob, key=lambda k: result.prob[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "3100abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bayes_net(bn, test_data, query_var):\n",
    "    \"\"\"\n",
    "    Evaluate the Bayesian Network on a test dataset.\n",
    "    \n",
    "    Args:\n",
    "        bn: Bayesian Network (BayesNet instance).\n",
    "        test_data: Test dataset (pandas DataFrame).\n",
    "        query_var: The target variable to predict.\n",
    "    \n",
    "    Returns:\n",
    "        Accuracy of the predictions as a float.\n",
    "    \"\"\"\n",
    "    correct = 0  # Count of correct predictions\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        # Build evidence dictionary from test row\n",
    "        evidence = {\n",
    "            \"AGE_GROUP\": row[\"AGE_GROUP\"],\n",
    "            \"SEX\": row[\"SEX\"],\n",
    "            \"OBESITY\": row[\"OBESITY\"],\n",
    "            \"DIABETES\": row[\"DIABETES\"],\n",
    "            \"PNEUMONIA\": row[\"PNEUMONIA\"],\n",
    "            \"ICU\": row[\"ICU\"]\n",
    "        }\n",
    "\n",
    "        # Predict the target variable\n",
    "        prediction = predict_bayes_net(bn, evidence, query_var)\n",
    "        \n",
    "        \n",
    "        # Check if the prediction matches the actual value\n",
    "        if prediction == row[query_var]:\n",
    "            correct += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / len(test_data)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6bb0adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bayes_net_with_time(bn, test_data, query_var):\n",
    "    \"\"\"\n",
    "    Evaluate the Bayesian Network on a test dataset and measure prediction time.\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Start Timing Predictions\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        evidence = {\n",
    "            \"AGE_GROUP\": row[\"AGE_GROUP\"],\n",
    "            \"SEX\": row[\"SEX\"],\n",
    "            \"OBESITY\": row[\"OBESITY\"],\n",
    "            \"DIABETES\": row[\"DIABETES\"],\n",
    "            \"PNEUMONIA\": row[\"PNEUMONIA\"],\n",
    "            \"ICU\": row[\"ICU\"]\n",
    "        }\n",
    "        prediction = predict_bayes_net(bn, evidence, query_var)\n",
    "        y_true.append(row[query_var])\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time\n",
    "\n",
    "    # Calculate Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    print(f\"Prediction Time: {prediction_time:.4f} seconds\")\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"prediction_time\": prediction_time\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c0bd46c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[124074   7245]\n",
      " [ 69890   8506]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.94      0.76    131319\n",
      "           1       0.54      0.11      0.18     78396\n",
      "\n",
      "    accuracy                           0.63    209715\n",
      "   macro avg       0.59      0.53      0.47    209715\n",
      "weighted avg       0.60      0.63      0.55    209715\n",
      "\n",
      "Prediction Time: 28.2940 seconds\n",
      "\n",
      "--- Final Results ---\n",
      "Training Time: 76.8942 seconds\n",
      "Prediction Time: 28.2940 seconds\n",
      "Accuracy: 63.22%\n"
     ]
    }
   ],
   "source": [
    "# Measure Prediction Time\n",
    "metrics = evaluate_bayes_net_with_time(classification_final, test_data, \"CLASIFFICATION_FINAL\")\n",
    "\n",
    "# Final Output\n",
    "print(\"\\n--- Final Results ---\")\n",
    "print(f\"Training Time: {training_time:.4f} seconds\")\n",
    "print(f\"Prediction Time: {metrics['prediction_time']:.4f} seconds\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29a5a8",
   "metadata": {},
   "source": [
    "# For Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "58eef703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpt_classification': {(1, 1, 1, 1): {1: 0.6524822695035462,\n",
       "   0: 0.3475177304964539},\n",
       "  (1, 1, 1, 2): {0: 0.5135019593872462, 1: 0.4864980406127538},\n",
       "  (1, 1, 2, 1): {0: 0.328998699609883, 1: 0.6710013003901171},\n",
       "  (1, 1, 2, 2): {0: 0.5990560540729518, 1: 0.40094394592704813},\n",
       "  (1, 1, 98, 1): {0: 0.42857142857142855, 1: 0.5714285714285714},\n",
       "  (1, 1, 98, 2): {0: 0.475, 1: 0.525},\n",
       "  (1, 2, 1, 1): {1: 0.6375121477162293, 0: 0.3624878522837707},\n",
       "  (1, 2, 1, 2): {0: 0.5469492144683961, 1: 0.45305078553160394},\n",
       "  (1, 2, 2, 1): {1: 0.5160128102481986, 0: 0.48398718975180144},\n",
       "  (1, 2, 2, 2): {1: 0.31796763023376756, 0: 0.6820323697662325},\n",
       "  (1, 2, 98, 1): {1: 0.5, 0: 0.5},\n",
       "  (1, 2, 98, 2): {0: 0.6729857819905213, 1: 0.32701421800947866},\n",
       "  (1, 98, 1, 1): {1: 1.0},\n",
       "  (1, 98, 1, 2): {0: 0.49122807017543857, 1: 0.5087719298245614},\n",
       "  (1, 98, 2, 1): {1: 0.5, 0: 0.5},\n",
       "  (1, 98, 2, 2): {1: 0.3333333333333333, 0: 0.6666666666666666},\n",
       "  (1, 98, 98, 1): {0: 0.43333333333333335, 1: 0.5666666666666667},\n",
       "  (1, 98, 98, 2): {0: 0.6015523932729625, 1: 0.3984476067270375},\n",
       "  (2, 1, 1, 1): {0: 0.3108108108108108, 1: 0.6891891891891891},\n",
       "  (2, 1, 1, 2): {0: 0.45563591462339037, 1: 0.5443640853766096},\n",
       "  (2, 1, 2, 1): {1: 0.7397572078907435, 0: 0.26024279210925644},\n",
       "  (2, 1, 2, 2): {0: 0.5326029927175806, 1: 0.46739700728241934},\n",
       "  (2, 1, 98, 1): {1: 0.3684210526315789, 0: 0.631578947368421},\n",
       "  (2, 1, 98, 2): {0: 0.5980392156862745, 1: 0.4019607843137255},\n",
       "  (2, 2, 1, 1): {0: 0.32940516273849607, 1: 0.6705948372615039},\n",
       "  (2, 2, 1, 2): {0: 0.4922714874043964, 1: 0.5077285125956036},\n",
       "  (2, 2, 2, 1): {0: 0.4076625053809729, 1: 0.5923374946190271},\n",
       "  (2, 2, 2, 2): {0: 0.6351305494730641, 1: 0.3648694505269358},\n",
       "  (2, 2, 98, 1): {1: 0.34210526315789475, 0: 0.6578947368421053},\n",
       "  (2, 2, 98, 2): {0: 0.6033898305084746, 1: 0.39661016949152544},\n",
       "  (2, 98, 1, 1): {1: 0.7142857142857143, 0: 0.2857142857142857},\n",
       "  (2, 98, 1, 2): {0: 0.4805194805194805, 1: 0.5194805194805194},\n",
       "  (2, 98, 2, 1): {0: 0.5, 1: 0.5},\n",
       "  (2, 98, 2, 2): {0: 0.563953488372093, 1: 0.436046511627907},\n",
       "  (2, 98, 98, 1): {1: 0.53125, 0: 0.46875},\n",
       "  (2, 98, 98, 2): {1: 0.4751434034416826, 0: 0.5248565965583174}},\n",
       " 'cpt_icu': {(1,): {2: 0.9006217829201495, 1: 0.09937821707985049},\n",
       "  (2,): {2: 0.9968022763829398, 1: 0.0031977236170602132}},\n",
       " 'cpt_pneumonia': {('20-40',): {2: 0.946088949366182, 1: 0.053911050633817945},\n",
       "  ('40-60',): {2: 0.8563595749001557, 1: 0.14364042509984432},\n",
       "  ('60-80',): {2: 0.6569643868165322, 1: 0.34303561318346776},\n",
       "  ('80+',): {2: 0.5684156671024956, 1: 0.4315843328975044},\n",
       "  ('<20',): {2: 0.9231421722293933, 1: 0.07685782777060668}},\n",
       " 'cpt_age_group': {(): {'40-60': 0.3698235115304608,\n",
       "   '20-40': 0.41612655194816806,\n",
       "   '60-80': 0.1284354455126868,\n",
       "   '<20': 0.06464568196312875,\n",
       "   '80+': 0.020968809045555602}},\n",
       " 'cpt_sex_group': {(): {1: 0.5005412094003543, 2: 0.4994587905996457}},\n",
       " 'cpt_obesity_group': {(): {2: 0.8474004067415141, 1: 0.1525995932584859}},\n",
       " 'cpt_diabetes_group': {(): {2: 0.8810495647675065, 1: 0.11895043523249355}}}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5fc82de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpts_to_json(cpts):\n",
    "    serializable_cpts = {}\n",
    "    for var, cpt in cpts.items():\n",
    "        serializable_cpts[var] = {\n",
    "            str(parent_comb): {str(k): v for k, v in target_probs.items()}\n",
    "            for parent_comb, target_probs in cpt.items()\n",
    "        }\n",
    "    return serializable_cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "874f01ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPTs saved successfully to covid_cpts.json!\n"
     ]
    }
   ],
   "source": [
    "# Save the CPTs to a JSON file\n",
    "cpt_json = cpts_to_json(cpts)\n",
    "with open(\"covid_cpts.json\", \"w\") as f:\n",
    "    json.dump(cpt_json, f, indent=4)\n",
    "print(\"CPTs saved successfully to covid_cpts.json!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "8b12c3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpt_classification': {'(1, 1, 1, 1)': {'1': 0.6524822695035462,\n",
       "   '0': 0.3475177304964539},\n",
       "  '(1, 1, 1, 2)': {'0': 0.5135019593872462, '1': 0.4864980406127538},\n",
       "  '(1, 1, 2, 1)': {'0': 0.328998699609883, '1': 0.6710013003901171},\n",
       "  '(1, 1, 2, 2)': {'0': 0.5990560540729518, '1': 0.40094394592704813},\n",
       "  '(1, 1, 98, 1)': {'0': 0.42857142857142855, '1': 0.5714285714285714},\n",
       "  '(1, 1, 98, 2)': {'0': 0.475, '1': 0.525},\n",
       "  '(1, 2, 1, 1)': {'1': 0.6375121477162293, '0': 0.3624878522837707},\n",
       "  '(1, 2, 1, 2)': {'0': 0.5469492144683961, '1': 0.45305078553160394},\n",
       "  '(1, 2, 2, 1)': {'1': 0.5160128102481986, '0': 0.48398718975180144},\n",
       "  '(1, 2, 2, 2)': {'1': 0.31796763023376756, '0': 0.6820323697662325},\n",
       "  '(1, 2, 98, 1)': {'1': 0.5, '0': 0.5},\n",
       "  '(1, 2, 98, 2)': {'0': 0.6729857819905213, '1': 0.32701421800947866},\n",
       "  '(1, 98, 1, 1)': {'1': 1.0},\n",
       "  '(1, 98, 1, 2)': {'0': 0.49122807017543857, '1': 0.5087719298245614},\n",
       "  '(1, 98, 2, 1)': {'1': 0.5, '0': 0.5},\n",
       "  '(1, 98, 2, 2)': {'1': 0.3333333333333333, '0': 0.6666666666666666},\n",
       "  '(1, 98, 98, 1)': {'0': 0.43333333333333335, '1': 0.5666666666666667},\n",
       "  '(1, 98, 98, 2)': {'0': 0.6015523932729625, '1': 0.3984476067270375},\n",
       "  '(2, 1, 1, 1)': {'0': 0.3108108108108108, '1': 0.6891891891891891},\n",
       "  '(2, 1, 1, 2)': {'0': 0.45563591462339037, '1': 0.5443640853766096},\n",
       "  '(2, 1, 2, 1)': {'1': 0.7397572078907435, '0': 0.26024279210925644},\n",
       "  '(2, 1, 2, 2)': {'0': 0.5326029927175806, '1': 0.46739700728241934},\n",
       "  '(2, 1, 98, 1)': {'1': 0.3684210526315789, '0': 0.631578947368421},\n",
       "  '(2, 1, 98, 2)': {'0': 0.5980392156862745, '1': 0.4019607843137255},\n",
       "  '(2, 2, 1, 1)': {'0': 0.32940516273849607, '1': 0.6705948372615039},\n",
       "  '(2, 2, 1, 2)': {'0': 0.4922714874043964, '1': 0.5077285125956036},\n",
       "  '(2, 2, 2, 1)': {'0': 0.4076625053809729, '1': 0.5923374946190271},\n",
       "  '(2, 2, 2, 2)': {'0': 0.6351305494730641, '1': 0.3648694505269358},\n",
       "  '(2, 2, 98, 1)': {'1': 0.34210526315789475, '0': 0.6578947368421053},\n",
       "  '(2, 2, 98, 2)': {'0': 0.6033898305084746, '1': 0.39661016949152544},\n",
       "  '(2, 98, 1, 1)': {'1': 0.7142857142857143, '0': 0.2857142857142857},\n",
       "  '(2, 98, 1, 2)': {'0': 0.4805194805194805, '1': 0.5194805194805194},\n",
       "  '(2, 98, 2, 1)': {'0': 0.5, '1': 0.5},\n",
       "  '(2, 98, 2, 2)': {'0': 0.563953488372093, '1': 0.436046511627907},\n",
       "  '(2, 98, 98, 1)': {'1': 0.53125, '0': 0.46875},\n",
       "  '(2, 98, 98, 2)': {'1': 0.4751434034416826, '0': 0.5248565965583174}},\n",
       " 'cpt_icu': {'(1,)': {'2': 0.9006217829201495, '1': 0.09937821707985049},\n",
       "  '(2,)': {'2': 0.9968022763829398, '1': 0.0031977236170602132}},\n",
       " 'cpt_pneumonia': {\"('20-40',)\": {'2': 0.946088949366182,\n",
       "   '1': 0.053911050633817945},\n",
       "  \"('40-60',)\": {'2': 0.8563595749001557, '1': 0.14364042509984432},\n",
       "  \"('60-80',)\": {'2': 0.6569643868165322, '1': 0.34303561318346776},\n",
       "  \"('80+',)\": {'2': 0.5684156671024956, '1': 0.4315843328975044},\n",
       "  \"('<20',)\": {'2': 0.9231421722293933, '1': 0.07685782777060668}},\n",
       " 'cpt_age_group': {'()': {'40-60': 0.3698235115304608,\n",
       "   '20-40': 0.41612655194816806,\n",
       "   '60-80': 0.1284354455126868,\n",
       "   '<20': 0.06464568196312875,\n",
       "   '80+': 0.020968809045555602}},\n",
       " 'cpt_sex_group': {'()': {'1': 0.5005412094003543, '2': 0.4994587905996457}},\n",
       " 'cpt_obesity_group': {'()': {'2': 0.8474004067415141,\n",
       "   '1': 0.1525995932584859}},\n",
       " 'cpt_diabetes_group': {'()': {'2': 0.8810495647675065,\n",
       "   '1': 0.11895043523249355}}}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
