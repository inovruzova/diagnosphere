{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f9d0f7",
   "metadata": {},
   "source": [
    "# Understanding Bayes Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c7526",
   "metadata": {},
   "source": [
    "We have:\n",
    "\n",
    "- Nodes: Variables (features like Age, Stress_Level and Mental_Health_Condition)\n",
    "- Edges: Dependencies between variables (Stress_Level -> Mental_Health_Condition)\n",
    "\n",
    "Bayes Nets encode the joint probability distribution of variables, allowing inference given evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8bb5f9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d23242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import getsource\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74c44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c95e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_data = pd.read_csv(\"../data/cleaned_breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e8dd81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    int64  \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(2)\n",
      "memory usage: 142.4 KB\n"
     ]
    }
   ],
   "source": [
    "mental_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84574990",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(\n",
    "    mental_data,\n",
    "    test_size=0.4,\n",
    "    random_state=42,\n",
    "    stratify=mental_data[\"diagnosis\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8e4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = mental_data.columns\n",
    "for col in categorical_columns:\n",
    "    train_data[col] = train_data[col].astype(\"category\")\n",
    "    test_data[col] = test_data[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55bed83",
   "metadata": {},
   "source": [
    "# Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05e60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(s, var, val):\n",
    "    \"\"\"Copy dict s and extend it by setting var to val; return copy.\"\"\"\n",
    "    return {**s, var: val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0462f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_with(event, evidence):\n",
    "    \"\"\"Is event consistent with the given evidence?\"\"\"\n",
    "    return all(evidence.get(k, v) == v\n",
    "               for k, v in event.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc77e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(p):\n",
    "    \"\"\"Return true with probability p.\"\"\"\n",
    "    return p > random.uniform(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a3fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbDist:\n",
    "    \"\"\"A discrete probability distribution. You name the random variable\n",
    "    in the constructor, then assign and query probability of values.\n",
    "    >>> P = ProbDist('Flip'); P['H'], P['T'] = 0.25, 0.75; P['H']\n",
    "    0.25\n",
    "    >>> P = ProbDist('X', {'lo': 125, 'med': 375, 'hi': 500})\n",
    "    >>> P['lo'], P['med'], P['hi']\n",
    "    (0.125, 0.375, 0.5)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, varname='?', freqs=None):\n",
    "        \"\"\"If freqs is given, it is a dictionary of values - frequency pairs,\n",
    "        then ProbDist is normalized.\"\"\"\n",
    "        self.prob = {}\n",
    "        self.varname = varname\n",
    "        self.values = []\n",
    "        if freqs:\n",
    "            for (v, p) in freqs.items():\n",
    "                self[v] = p\n",
    "            self.normalize()\n",
    "\n",
    "    def __getitem__(self, val):\n",
    "        \"\"\"Given a value, return P(value).\"\"\"\n",
    "        try:\n",
    "            return self.prob[val]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "    def __setitem__(self, val, p):\n",
    "        \"\"\"Set P(val) = p.\"\"\"\n",
    "        if val not in self.values:\n",
    "            self.values.append(val)\n",
    "        self.prob[val] = p\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"Make sure the probabilities of all values sum to 1.\n",
    "        Returns the normalized distribution.\n",
    "        Raises a ZeroDivisionError if the sum of the values is 0.\"\"\"\n",
    "        total = sum(self.prob.values())\n",
    "        if not np.isclose(total, 1.0):\n",
    "            for val in self.prob:\n",
    "                self.prob[val] /= total\n",
    "        return self\n",
    "\n",
    "    def show_approx(self, numfmt='{:.3g}'):\n",
    "        \"\"\"Show the probabilities rounded and sorted by key, for the\n",
    "        sake of portable doctests.\"\"\"\n",
    "        return ', '.join([('{}: ' + numfmt).format(v, p)\n",
    "                          for (v, p) in sorted(self.prob.items())])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({})\".format(self.varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f7de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointProbDist(ProbDist):\n",
    "    \"\"\"A discrete probability distribute over a set of variables.\n",
    "    >>> P = JointProbDist(['X', 'Y']); P[1, 1] = 0.25\n",
    "    >>> P[1, 1]\n",
    "    0.25\n",
    "    >>> P[dict(X=0, Y=1)] = 0.5\n",
    "    >>> P[dict(X=0, Y=1)]\n",
    "    0.5\"\"\"\n",
    "\n",
    "    def __init__(self, variables):\n",
    "        self.prob = {}\n",
    "        self.variables = variables\n",
    "        self.vals = defaultdict(list)\n",
    "\n",
    "    def __getitem__(self, values):\n",
    "        \"\"\"Given a tuple or dict of values, return P(values).\"\"\"\n",
    "        values = event_values(values, self.variables)\n",
    "        return ProbDist.__getitem__(self, values)\n",
    "\n",
    "    def __setitem__(self, values, p):\n",
    "        \"\"\"Set P(values) = p.  Values can be a tuple or a dict; it must\n",
    "        have a value for each of the variables in the joint. Also keep track\n",
    "        of the values we have seen so far for each variable.\"\"\"\n",
    "        values = event_values(values, self.variables)\n",
    "        self.prob[values] = p\n",
    "        for var, val in zip(self.variables, values):\n",
    "            if val not in self.vals[var]:\n",
    "                self.vals[var].append(val)\n",
    "\n",
    "    def values(self, var):\n",
    "        \"\"\"Return the set of possible values for a variable.\"\"\"\n",
    "        return self.vals[var]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"P({})\".format(self.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e82e018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNode:\n",
    "    \"\"\"A conditional probability distribution for a boolean variable,\n",
    "    P(X | parents). Part of a BayesNet.\"\"\"\n",
    "\n",
    "    def __init__(self, X, parents, cpt):\n",
    "        \"\"\"X is a variable name, and parents a sequence of variable\n",
    "        names or a space-separated string.  cpt, the conditional\n",
    "        probability table, takes one of these forms:\n",
    "\n",
    "        * A number, the unconditional probability P(X=true). You can\n",
    "          use this form when there are no parents.\n",
    "\n",
    "        * A dict {v: p, ...}, the conditional probability distribution\n",
    "          P(X=true | parent=v) = p. When there's just one parent.\n",
    "\n",
    "        * A dict {(v1, v2, ...): p, ...}, the distribution P(X=true |\n",
    "          parent1=v1, parent2=v2, ...) = p. Each key must have as many\n",
    "          values as there are parents. You can use this form always;\n",
    "          the first two are just conveniences.\n",
    "\n",
    "        In all cases the probability of X being false is left implicit,\n",
    "        since it follows from P(X=true).\n",
    "\n",
    "        >>> X = BayesNode('X', '', 0.2)\n",
    "        >>> Y = BayesNode('Y', 'P', {T: 0.2, F: 0.7})\n",
    "        >>> Z = BayesNode('Z', 'P Q',\n",
    "        ...    {(T, T): 0.2, (T, F): 0.3, (F, T): 0.5, (F, F): 0.7})\n",
    "        \"\"\"\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "\n",
    "        # We store the table always in the third form above.\n",
    "        if isinstance(cpt, (float, int)):  # no parents, 0-tuple\n",
    "            cpt = {(): cpt}\n",
    "        elif isinstance(cpt, dict):\n",
    "            # one parent, 1-tuple\n",
    "            if cpt and isinstance(list(cpt.keys())[0], bool):\n",
    "                cpt = {(v,): p for v, p in cpt.items()}\n",
    "\n",
    "        assert isinstance(cpt, dict)\n",
    "        for vs, p in cpt.items():\n",
    "            assert isinstance(vs, tuple) and len(vs) == len(parents)\n",
    "            assert all(isinstance(v, bool) for v in vs)\n",
    "            assert 0 <= p <= 1\n",
    "\n",
    "        self.variable = X\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.children = []\n",
    "\n",
    "    def p(self, value, event):\n",
    "        \"\"\"Return the conditional probability\n",
    "        P(X=value | parents=parent_values), where parent_values\n",
    "        are the values of parents in event. (event must assign each\n",
    "        parent a value.)\n",
    "        >>> bn = BayesNode('X', 'Burglary', {T: 0.2, F: 0.625})\n",
    "        >>> bn.p(False, {'Burglary': False, 'Earthquake': True})\n",
    "        0.375\"\"\"\n",
    "        assert isinstance(value, bool)\n",
    "        ptrue = self.cpt[event_values(event, self.parents)]\n",
    "        return ptrue if value else 1 - ptrue\n",
    "\n",
    "    def sample(self, event):\n",
    "        \"\"\"Sample from the distribution for this variable conditioned\n",
    "        on event's values for parent_variables. That is, return True/False\n",
    "        at random according with the conditional probability given the\n",
    "        parents.\"\"\"\n",
    "        return probability(self.p(True, event))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr((self.variable, ' '.join(self.parents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d67948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_sampling(probabilities):\n",
    "    \"\"\"Randomly sample an outcome from a probability distribution.\"\"\"\n",
    "    total = sum(probabilities.values())\n",
    "    r = random.uniform(0, total)\n",
    "    cumulative = 0\n",
    "    for outcome, prob in probabilities.items():\n",
    "        cumulative += prob\n",
    "        if r <= cumulative:\n",
    "            return outcome\n",
    "    return None  # Should not reach here if probabilities are normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7159ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassBayesNode:\n",
    "    \"\"\"A Bayesian node for multi-class variables.\"\"\"\n",
    "    def __init__(self, X, parents, cpt):\n",
    "        \"\"\"\n",
    "        X: Name of the variable.\n",
    "        parents: List of parent variable names.\n",
    "        cpt: Conditional probability table, mapping tuples of parent values to\n",
    "             dictionaries of target probabilities.\n",
    "        \"\"\"\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "        self.variable = X\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.children = []\n",
    "\n",
    "    def p(self, value, event):\n",
    "        \"\"\"Return the conditional probability P(X=value | parents=parent_values).\"\"\"\n",
    "        parent_values = tuple(event.get(p, None) for p in self.parents)\n",
    "        probabilities = self.cpt.get(parent_values, {})\n",
    "        return probabilities.get(value, 0)  # Default to 0 if value not found\n",
    "\n",
    "    def sample(self, event):\n",
    "        \"\"\"Sample from the distribution for this variable given parent values.\"\"\"\n",
    "        parent_values = tuple(event.get(p, None) for p in self.parents)\n",
    "        probabilities = self.cpt.get(parent_values, {})\n",
    "        return probability_sampling(probabilities)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr((self.variable, ' '.join(self.parents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1b41a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesNet:\n",
    "    \"\"\"Bayesian network containing only boolean-variable or multi-class nodes.\"\"\"\n",
    "    \n",
    "    def __init__(self, node_specs=None):\n",
    "        \"\"\"Nodes must be ordered with parents before children.\"\"\"\n",
    "        self.nodes = []\n",
    "        self.variables = []\n",
    "        node_specs = node_specs or []\n",
    "        for node_spec in node_specs:\n",
    "            self.add(node_spec)\n",
    "\n",
    "    def add(self, node_spec):\n",
    "        \"\"\"Add a node to the net. Supports both pre-constructed nodes and node specs.\"\"\"\n",
    "        if isinstance(node_spec, (BayesNode, MultiClassBayesNode)):\n",
    "            # If already a node, add it directly\n",
    "            node = node_spec\n",
    "        else:\n",
    "            # Otherwise, initialize a new node\n",
    "            node = BayesNode(*node_spec)\n",
    "\n",
    "        assert node.variable not in self.variables\n",
    "        assert all((parent in self.variables) for parent in node.parents)\n",
    "\n",
    "        self.nodes.append(node)\n",
    "        self.variables.append(node.variable)\n",
    "\n",
    "        # Register children for the parent nodes\n",
    "        for parent in node.parents:\n",
    "            self.variable_node(parent).children.append(node)\n",
    "\n",
    "    def variable_node(self, var):\n",
    "        \"\"\"Return the node for the variable named var.\"\"\"\n",
    "        for n in self.nodes:\n",
    "            if n.variable == var:\n",
    "                return n\n",
    "        raise Exception(f\"No such variable: {var}\")\n",
    "\n",
    "    def variable_values(self, var):\n",
    "        \"\"\"Return the domain of var.\"\"\"\n",
    "        return [True, False]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BayesNet({self.nodes!r})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cacc07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_factor(var, e, bn):\n",
    "    \"\"\"Return the factor for var in bn's joint distribution given e.\n",
    "    That is, bn's full joint distribution, projected to accord with e,\n",
    "    is the pointwise product of these factors for bn's variables.\"\"\"\n",
    "    node = bn.variable_node(var)\n",
    "    variables = [X for X in [var] + node.parents if X not in e]\n",
    "    cpt = {event_values(e1, variables): node.p(e1[var], e1)\n",
    "           for e1 in all_events(variables, bn, e)}\n",
    "    return Factor(variables, cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c01ebbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factor:\n",
    "    \"\"\"A factor in a joint distribution.\"\"\"\n",
    "\n",
    "    def __init__(self, variables, cpt):\n",
    "        self.variables = variables\n",
    "        self.cpt = cpt\n",
    "\n",
    "    def pointwise_product(self, other, bn):\n",
    "        \"\"\"Multiply two factors, combining their variables.\"\"\"\n",
    "        variables = list(set(self.variables) | set(other.variables))\n",
    "        cpt = {event_values(e, variables): self.p(e) * other.p(e) for e in all_events(variables, bn, {})}\n",
    "        return Factor(variables, cpt)\n",
    "\n",
    "    def sum_out(self, var, bn):\n",
    "        \"\"\"Make a factor eliminating var by summing over its values.\"\"\"\n",
    "        variables = [X for X in self.variables if X != var]\n",
    "        cpt = {event_values(e, variables): sum(self.p(extend(e, var, val)) for val in bn.variable_values(var))\n",
    "               for e in all_events(variables, bn, {})}\n",
    "        return Factor(variables, cpt)\n",
    "\n",
    "    def normalize(self):\n",
    "        \"\"\"Return my probabilities; must be down to one variable.\"\"\"\n",
    "        assert len(self.variables) == 1\n",
    "        return ProbDist(self.variables[0], {k: v for ((k,), v) in self.cpt.items()})\n",
    "\n",
    "    def p(self, e):\n",
    "        \"\"\"Look up my value tabulated for e.\"\"\"\n",
    "        return self.cpt[event_values(e, self.variables)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d56a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_all(variables, e, bn):\n",
    "    \"\"\"Return the sum of those entries in P(variables | e{others})\n",
    "    consistent with e, where P is the joint distribution represented\n",
    "    by bn, and e{others} means e restricted to bn's other variables\n",
    "    (the ones other than variables). Parents must precede children in variables.\"\"\"\n",
    "    if not variables:\n",
    "        return 1.0\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    Ynode = bn.variable_node(Y)\n",
    "    if Y in e:\n",
    "        return Ynode.p(e[Y], e) * enumerate_all(rest, e, bn)\n",
    "    else:\n",
    "        return sum(Ynode.p(y, e) * enumerate_all(rest, extend(e, Y, y), bn)\n",
    "                   for y in bn.variable_values(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29b1ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumeration_ask(X, e, bn):\n",
    "    \"\"\"Return the conditional probability distribution of variable X\n",
    "    given evidence e, from BayesNet bn. [Figure 14.9]\n",
    "    >>> enumeration_ask('Burglary', dict(JohnCalls=T, MaryCalls=T), burglary\n",
    "    ...  ).show_approx()\n",
    "    'False: 0.716, True: 0.284'\"\"\"\n",
    "    assert X not in e, \"Query variable must be distinct from evidence\"\n",
    "    Q = ProbDist(X)\n",
    "    for xi in bn.variable_values(X):\n",
    "        Q[xi] = enumerate_all(bn.variables, extend(e, X, xi), bn)\n",
    "    return Q.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2a85ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elimination_ask(X, e, bn):\n",
    "    \"\"\"Compute bn's P(X|e) by variable elimination. [Figure 14.11]\n",
    "    >>> elimination_ask('Burglary', dict(JohnCalls=T, MaryCalls=T), burglary\n",
    "    ...  ).show_approx()\n",
    "    'False: 0.716, True: 0.284'\"\"\"\n",
    "    assert X not in e, \"Query variable must be distinct from evidence\"\n",
    "    factors = []\n",
    "    for var in reversed(bn.variables):\n",
    "        factors.append(make_factor(var, e, bn))\n",
    "        if is_hidden(var, X, e):\n",
    "            factors = sum_out(var, factors, bn)\n",
    "    return pointwise_product(factors, bn).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df22d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_sample(bn):\n",
    "    \"\"\"Randomly sample from bn's full joint distribution. The result\n",
    "    is a {variable: value} dict. [Figure 14.13]\"\"\"\n",
    "    event = {}\n",
    "    for node in bn.nodes:\n",
    "        event[node.variable] = node.sample(event)\n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b4189e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection_sampling(X, e, bn, N=10000):\n",
    "    \"\"\"Estimate the probability distribution of variable X given\n",
    "    evidence e in BayesNet bn, using N samples.  [Figure 14.14]\n",
    "    Raises a ZeroDivisionError if all the N samples are rejected,\n",
    "    i.e., inconsistent with e.\n",
    "    >>> random.seed(47)\n",
    "    >>> rejection_sampling('Burglary', dict(JohnCalls=T, MaryCalls=T),\n",
    "    ...   burglary, 10000).show_approx()\n",
    "    'False: 0.7, True: 0.3'\n",
    "    \"\"\"\n",
    "    counts = {x: 0 for x in bn.variable_values(X)}  # bold N in [Figure 14.14]\n",
    "    for j in range(N):\n",
    "        sample = prior_sample(bn)  # boldface x in [Figure 14.14]\n",
    "        if consistent_with(sample, e):\n",
    "            counts[sample[X]] += 1\n",
    "    return ProbDist(X, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60855c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_weighting(X, e, bn, N=10000):\n",
    "    \"\"\"Estimate the probability distribution of variable X given\n",
    "    evidence e in BayesNet bn.  [Figure 14.15]\n",
    "    >>> random.seed(1017)\n",
    "    >>> likelihood_weighting('Burglary', dict(JohnCalls=T, MaryCalls=T),\n",
    "    ...   burglary, 10000).show_approx()\n",
    "    'False: 0.702, True: 0.298'\n",
    "    \"\"\"\n",
    "    W = {x: 0 for x in bn.variable_values(X)}\n",
    "    for j in range(N):\n",
    "        sample, weight = weighted_sample(bn, e)  # boldface x, w in [Figure 14.15]\n",
    "        W[sample[X]] += weight\n",
    "    return ProbDist(X, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c441e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_ask(X, e, bn, N=1000):\n",
    "    \"\"\"[Figure 14.16]\"\"\"\n",
    "    assert X not in e, \"Query variable must be distinct from evidence\"\n",
    "    counts = {x: 0 for x in bn.variable_values(X)}  # bold N in [Figure 14.16]\n",
    "    Z = [var for var in bn.variables if var not in e]\n",
    "    state = dict(e)  # boldface x in [Figure 14.16]\n",
    "    for Zi in Z:\n",
    "        state[Zi] = random.choice(bn.variable_values(Zi))\n",
    "    for j in range(N):\n",
    "        for Zi in Z:\n",
    "            state[Zi] = markov_blanket_sample(Zi, state, bn)\n",
    "            counts[state[X]] += 1\n",
    "    return ProbDist(X, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4759d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise_product(self, other, bn):\n",
    "        \"\"\"Multiply two factors, combining their variables.\"\"\"\n",
    "        variables = list(set(self.variables) | set(other.variables))\n",
    "        cpt = {event_values(e, variables): self.p(e) * other.p(e)\n",
    "               for e in all_events(variables, bn, {})}\n",
    "        return Factor(variables, cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6c8285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_out(self, var, bn):\n",
    "        \"\"\"Make a factor eliminating var by summing over its values.\"\"\"\n",
    "        variables = [X for X in self.variables if X != var]\n",
    "        cpt = {event_values(e, variables): sum(self.p(extend(e, var, val))\n",
    "                                               for val in bn.variable_values(var))\n",
    "               for e in all_events(variables, bn, {})}\n",
    "        return Factor(variables, cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bc0e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_values(event, variables):\n",
    "    \"\"\"Return a tuple of the values of variables in event.\n",
    "    >>> event_values ({'A': 10, 'B': 9, 'C': 8}, ['C', 'A'])\n",
    "    (8, 10)\n",
    "    >>> event_values ((1, 2), ['C', 'A'])\n",
    "    (1, 2)\n",
    "    \"\"\"\n",
    "    if isinstance(event, tuple) and len(event) == len(variables):\n",
    "        return event\n",
    "    else:\n",
    "        return tuple([event[var] for var in variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7389904",
   "metadata": {},
   "source": [
    "# Design the Network Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65308c",
   "metadata": {},
   "source": [
    "Find dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6c62c2",
   "metadata": {},
   "source": [
    "# Estimate Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483d1bf",
   "metadata": {},
   "source": [
    "If a node is a root node, then estimate probability directly from the data. Estimate conditional probabilities based on parent for non-root nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "951ae0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cpt(data, target, parents, alpha=1):\n",
    "    \"\"\"\n",
    "    Compute CPT with Laplace smoothing.\n",
    "    \n",
    "    Args:\n",
    "        data: pandas DataFrame (training data)\n",
    "        target: str, target variable\n",
    "        parents: list of parent variable names\n",
    "        alpha: smoothing parameter (default=1)\n",
    "    \n",
    "    Returns:\n",
    "        cpt: dict { parent_values_tuple: { target_value: probability } }\n",
    "    \"\"\"\n",
    "    target_values = data[target].cat.categories\n",
    "\n",
    "    if not parents:\n",
    "        # Marginal distribution of target\n",
    "        counts = defaultdict(lambda: alpha)\n",
    "        for val in data[target]:\n",
    "            counts[val] += 1\n",
    "        total = sum(counts.values())\n",
    "        cpt = {(): {tv: counts[tv]/total for tv in counts}}\n",
    "        return cpt\n",
    "\n",
    "    # Determine possible parent combinations\n",
    "    from itertools import product\n",
    "    parent_values_list = [data[p].cat.categories for p in parents]\n",
    "    parent_combinations = list(product(*parent_values_list)) if parents else [()]\n",
    "\n",
    "    # Initialize counts with alpha\n",
    "    counts = {pc: defaultdict(lambda: alpha) for pc in parent_combinations}\n",
    "\n",
    "    # Count occurrences\n",
    "    for _, row in data.iterrows():\n",
    "        pv = tuple(row[p] for p in parents) if parents else ()\n",
    "        tv = row[target]\n",
    "        counts[pv][tv] += 1\n",
    "\n",
    "    # Compute probabilities\n",
    "    cpt = {}\n",
    "    for pc in parent_combinations:\n",
    "        total = sum(counts[pc].values())\n",
    "        cpt[pc] = {tv: (counts[pc][tv] / total) for tv in counts[pc]}\n",
    "        \n",
    "    return cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a77f5d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "628ab034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_cpts(train_data):\n",
    "    \"\"\"\n",
    "    Compute all CPTs and record the time taken.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start timing\n",
    "    \n",
    "    # Compute CPTs\n",
    "    cpt_diagnosis = compute_cpt(train_data, 'diagnosis', [])\n",
    "    cpt_concave_points = compute_cpt(train_data, 'concave points_mean', ['diagnosis'])\n",
    "    cpt_perimeter = compute_cpt(train_data, 'perimeter_mean', ['diagnosis'])\n",
    "    cpt_radius = compute_cpt(train_data, 'radius_mean', ['diagnosis'])\n",
    "    cpt_concavity = compute_cpt(train_data, 'concavity_mean', ['diagnosis', 'concave points_mean'])\n",
    "    cpt_texture = compute_cpt(train_data, 'texture_mean', ['diagnosis'])\n",
    "\n",
    "    cpt_area = compute_cpt(train_data, 'area_mean', ['perimeter_mean'])\n",
    "    cpt_compactness = compute_cpt(train_data, 'compactness_mean', ['concavity_mean'])\n",
    "    cpt_smoothness = compute_cpt(train_data, 'smoothness_mean', ['concavity_mean'])\n",
    "    cpt_symmetry = compute_cpt(train_data, 'symmetry_mean', ['compactness_mean'])\n",
    "    cpt_fractal = compute_cpt(train_data, 'fractal_dimension_mean', ['symmetry_mean'])\n",
    "    \n",
    "    end_time = time.time()  # End timing\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"Training Time (CPT Computation): {training_time:.4f} seconds\")\n",
    "\n",
    "    return {\n",
    "        \"cpt_diagnosis\": cpt_diagnosis,\n",
    "        \"cpt_concave_points\": cpt_concave_points,\n",
    "        \"cpt_perimeter\": cpt_perimeter,\n",
    "        \"cpt_radius\": cpt_radius,\n",
    "        \"cpt_concavity\": cpt_concavity,\n",
    "        \"cpt_texture\": cpt_texture,\n",
    "        \"cpt_area\": cpt_area,\n",
    "        \"cpt_compactness\": cpt_compactness,\n",
    "        \"cpt_smoothness\": cpt_smoothness,\n",
    "        \"cpt_symmetry\": cpt_symmetry,\n",
    "        \"cpt_fractal\": cpt_fractal\n",
    "    }, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e16d5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ('diagnosis', 'concave points_mean'),\n",
    "    # ('diagnosis', 'perimeter_mean'),\n",
    "    # ('diagnosis', 'radius_mean'),\n",
    "    # ('diagnosis', 'concavity_mean'),\n",
    "    # ('diagnosis', 'texture_mean'),\n",
    "    \n",
    "    # ('concave points_mean', 'concavity_mean'),\n",
    "    # ('concavity_mean', 'compactness_mean'),\n",
    "    # ('concavity_mean', 'smoothness_mean'),\n",
    "    \n",
    "    # ('radius_mean', 'perimeter_mean'),\n",
    "    # ('perimeter_mean', 'area_mean'),\n",
    "    \n",
    "    # ('compactness_mean', 'symmetry_mean'),\n",
    "    # ('symmetry_mean', 'fractal_dimension_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ca23062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpt_diagnosis = compute_cpt(train_data, 'diagnosis', [])\n",
    "# cpt_concave_points = compute_cpt(train_data, 'concave points_mean', ['diagnosis'])\n",
    "# cpt_perimeter = compute_cpt(train_data, 'perimeter_mean', ['diagnosis'])\n",
    "# cpt_radius = compute_cpt(train_data, 'radius_mean', ['diagnosis'])\n",
    "# cpt_concavity = compute_cpt(train_data, 'concavity_mean', ['diagnosis', 'concave points_mean'])\n",
    "# cpt_texture = compute_cpt(train_data, 'texture_mean', ['diagnosis'])\n",
    "\n",
    "# cpt_area = compute_cpt(train_data, 'area_mean', ['perimeter_mean'])\n",
    "# cpt_compactness = compute_cpt(train_data, 'compactness_mean', ['concavity_mean'])\n",
    "# cpt_smoothness = compute_cpt(train_data, 'smoothness_mean', ['concavity_mean'])\n",
    "# cpt_symmetry = compute_cpt(train_data, 'symmetry_mean', ['compactness_mean'])\n",
    "# cpt_fractal = compute_cpt(train_data, 'fractal_dimension_mean', ['symmetry_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea9488",
   "metadata": {},
   "source": [
    "# Implement Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae3782a",
   "metadata": {},
   "source": [
    "Use the chain rule of probability to predict target given evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "652cf98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time (CPT Computation): 0.1161 seconds\n"
     ]
    }
   ],
   "source": [
    "cpts, training_time = compute_all_cpts(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c0a6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_node = MultiClassBayesNode(\"diagnosis\", [], cpts['cpt_diagnosis'])\n",
    "\n",
    "concave_points_node = MultiClassBayesNode(\n",
    "    \"concave points_mean\", [\"diagnosis\"], cpts['cpt_concave_points']\n",
    ")\n",
    "perimeter_node = MultiClassBayesNode(\"perimeter_mean\", [\"diagnosis\"], cpts['cpt_perimeter'])\n",
    "radius_node = MultiClassBayesNode(\"radius_mean\", [\"diagnosis\"], cpts['cpt_radius'])\n",
    "concavity_node = MultiClassBayesNode(\n",
    "    \"concavity_mean\", [\"diagnosis\", \"concave points_mean\"], cpts['cpt_concavity'])\n",
    "\n",
    "texture_node = MultiClassBayesNode(\"texture_mean\", [\"diagnosis\"], cpts['cpt_texture'])\n",
    "\n",
    "area_node = MultiClassBayesNode(\"area_mean\", [\"perimeter_mean\"], cpts['cpt_area'])\n",
    "compactness_node = MultiClassBayesNode(\"compactness_mean\", [\"concavity_mean\"], cpts['cpt_compactness'])\n",
    "smoothness_node = MultiClassBayesNode(\"smoothness_mean\", [\"concavity_mean\"], cpts['cpt_smoothness'])\n",
    "symmetry_node = MultiClassBayesNode(\"symmetry_mean\", [\"compactness_mean\"], cpts['cpt_symmetry'])\n",
    "fractal_node = MultiClassBayesNode(\"fractal_dimension_mean\", [\"symmetry_mean\"], cpts['cpt_fractal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd09a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_bn = BayesNet([\n",
    "    diagnosis_node,\n",
    "    concave_points_node,\n",
    "    perimeter_node,\n",
    "    radius_node,\n",
    "    concavity_node,\n",
    "    texture_node,\n",
    "    area_node,\n",
    "    compactness_node,\n",
    "    smoothness_node,\n",
    "    symmetry_node,\n",
    "    fractal_node\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1614601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesNet([('diagnosis', ''), ('concave points_mean', 'diagnosis'), ('perimeter_mean', 'diagnosis'), ('radius_mean', 'diagnosis'), ('concavity_mean', 'diagnosis concave points_mean'), ('texture_mean', 'diagnosis'), ('area_mean', 'perimeter_mean'), ('compactness_mean', 'concavity_mean'), ('smoothness_mean', 'concavity_mean'), ('symmetry_mean', 'compactness_mean'), ('fractal_dimension_mean', 'symmetry_mean')])\n"
     ]
    }
   ],
   "source": [
    "print(diagnosis_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4477f",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ff130e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bayes_net(bn, evidence, query_var):\n",
    "    \"\"\"\n",
    "    Predict the most likely value of a query variable given evidence using the Bayesian Network.\n",
    "    \n",
    "    Args:\n",
    "        bn: Bayesian network.\n",
    "        evidence: Dictionary of evidence variables and their values.\n",
    "        query_var: Variable to predict.\n",
    "    \n",
    "    Returns:\n",
    "        The most likely value of the query variable.\n",
    "    \"\"\"\n",
    "    result = enumeration_ask(query_var, evidence, bn)\n",
    "    return max(result.prob, key=lambda k: result.prob[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3100abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bayes_net(bn, test_data, query_var):\n",
    "    \"\"\"\n",
    "    Evaluate the Bayesian Network on a test dataset.\n",
    "    \n",
    "    Args:\n",
    "        bn: Bayesian Network (BayesNet instance).\n",
    "        test_data: Test dataset (pandas DataFrame).\n",
    "        query_var: The target variable to predict.\n",
    "    \n",
    "    Returns:\n",
    "        Accuracy of the predictions as a float.\n",
    "    \"\"\"\n",
    "    correct = 0  # Count of correct predictions\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        # Build evidence dictionary from test row\n",
    "        evidence = {\n",
    "            \"concave points_mean\": row[\"concave points_mean\"],\n",
    "            \"perimeter_mean\": row[\"perimeter_mean\"],\n",
    "            \"radius_mean\": row[\"radius_mean\"],\n",
    "            \"concavity_mean\": row[\"concavity_mean\"],\n",
    "            \"texture_mean\": row[\"texture_mean\"],\n",
    "            \"area_mean\": row[\"area_mean\"],\n",
    "            \"compactness_mean\": row[\"compactness_mean\"],\n",
    "            \"smoothness_mean\": row[\"smoothness_mean\"],\n",
    "            \"symmetry_mean\": row[\"symmetry_mean\"],\n",
    "            \"fractal_dimension_mean\": row[\"fractal_dimension_mean\"],\n",
    "        }\n",
    "\n",
    "        # Predict the target variable\n",
    "        prediction = predict_bayes_net(bn, evidence, query_var)\n",
    "        \n",
    "        \n",
    "        # Check if the prediction matches the actual value\n",
    "        if prediction == row[query_var]:\n",
    "            correct += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / len(test_data)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65fe8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Bayesian Network: 90.35%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Bayesian Network on the test dataset\n",
    "query_var = \"diagnosis\"\n",
    "accuracy = evaluate_bayes_net(diagnosis_bn, test_data, query_var)\n",
    "\n",
    "print(f\"Accuracy of Bayesian Network: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4de23a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def evaluate_bayes_net(bn, test_data, query_var):\n",
    "    \"\"\"\n",
    "    Evaluate the Bayesian Network on a test dataset and compute various metrics.\n",
    "\n",
    "    Args:\n",
    "        bn: Bayesian Network (BayesNet instance).\n",
    "        test_data: Test dataset (pandas DataFrame).\n",
    "        query_var: The target variable to predict.\n",
    "\n",
    "    Returns:\n",
    "        metrics: A dictionary containing accuracy, and prints out confusion matrix\n",
    "                 and classification report (precision, recall, f1).\n",
    "    \"\"\"\n",
    "\n",
    "    # Start Timing Predictions\n",
    "    start_time = time.time()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        # Build evidence dictionary from test row\n",
    "        # Note: Adjust the evidence set according to what you want to condition on.\n",
    "        evidence = {\n",
    "            \"concave points_mean\": row[\"concave points_mean\"],\n",
    "            \"perimeter_mean\": row[\"perimeter_mean\"],\n",
    "            \"radius_mean\": row[\"radius_mean\"],\n",
    "            \"concavity_mean\": row[\"concavity_mean\"],\n",
    "            \"texture_mean\": row[\"texture_mean\"],\n",
    "            \"area_mean\": row[\"area_mean\"],\n",
    "            \"compactness_mean\": row[\"compactness_mean\"],\n",
    "            \"smoothness_mean\": row[\"smoothness_mean\"],\n",
    "            \"symmetry_mean\": row[\"symmetry_mean\"],\n",
    "            \"fractal_dimension_mean\": row[\"fractal_dimension_mean\"],\n",
    "        }\n",
    "\n",
    "        # Predict the target variable\n",
    "        prediction = predict_bayes_net(bn, evidence, query_var)\n",
    "\n",
    "        y_true.append(row[query_var])\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time    \n",
    "\n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    print(f\"Prediction Time: {prediction_time:.4f} seconds\")\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc,\n",
    "        \"prediction_time\": prediction_time\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "109c0492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[134   9]\n",
      " [ 13  72]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.94      0.92       143\n",
      "         1.0       0.89      0.85      0.87        85\n",
      "\n",
      "    accuracy                           0.90       228\n",
      "   macro avg       0.90      0.89      0.90       228\n",
      "weighted avg       0.90      0.90      0.90       228\n",
      "\n",
      "Prediction Time: 0.0253 seconds\n",
      "Accuracy: 0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_bayes_net(diagnosis_bn, test_data, \"diagnosis\")\n",
    "print(\"Accuracy:\", metrics[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115034ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a3548bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpt_diagnosis': {(): {1: 0.37317784256559766, 0: 0.6268221574344023}},\n",
       " 'cpt_concave_points': {(0,): {0.0: 0.5253456221198156,\n",
       "   1.0: 0.42857142857142855,\n",
       "   2.0: 0.04608294930875576},\n",
       "  (1,): {2.0: 0.7923076923076923,\n",
       "   1.0: 0.18461538461538463,\n",
       "   0.0: 0.023076923076923078}},\n",
       " 'cpt_perimeter': {(0,): {0.0: 0.5253456221198156,\n",
       "   1.0: 0.41013824884792627,\n",
       "   2.0: 0.06451612903225806},\n",
       "  (1,): {2.0: 0.8, 1.0: 0.15384615384615385, 0.0: 0.046153846153846156}},\n",
       " 'cpt_radius': {(0,): {0.0: 0.5023041474654378,\n",
       "   1.0: 0.42857142857142855,\n",
       "   2.0: 0.06912442396313365},\n",
       "  (1,): {2.0: 0.8, 1.0: 0.14615384615384616, 0.0: 0.05384615384615385}},\n",
       " 'cpt_concavity': {(0, 0.0): {0.0: 0.7844827586206896,\n",
       "   1.0: 0.19827586206896552,\n",
       "   2.0: 0.017241379310344827},\n",
       "  (0, 1.0): {1.0: 0.6631578947368421,\n",
       "   0.0: 0.24210526315789474,\n",
       "   2.0: 0.09473684210526316},\n",
       "  (0, 2.0): {2.0: 0.6363636363636364, 1.0: 0.36363636363636365},\n",
       "  (1, 0.0): {0.0: 1.0},\n",
       "  (1, 1.0): {0.0: 0.19230769230769232,\n",
       "   1.0: 0.5769230769230769,\n",
       "   2.0: 0.23076923076923078},\n",
       "  (1, 2.0): {2.0: 0.8942307692307693, 1.0: 0.10576923076923077}},\n",
       " 'cpt_texture': {(0,): {1.0: 0.3271889400921659,\n",
       "   0.0: 0.4423963133640553,\n",
       "   2.0: 0.2304147465437788},\n",
       "  (1,): {2.0: 0.5538461538461539,\n",
       "   1.0: 0.36923076923076925,\n",
       "   0.0: 0.07692307692307693}},\n",
       " 'cpt_area': {(0.0,): {0.0: 0.9583333333333334, 1.0: 0.041666666666666664},\n",
       "  (1.0,): {1.0: 0.9272727272727272,\n",
       "   0.0: 0.01818181818181818,\n",
       "   2.0: 0.05454545454545454},\n",
       "  (2.0,): {1.0: 0.0423728813559322, 2.0: 0.9576271186440678}},\n",
       " 'cpt_compactness': {(0.0,): {0.0: 0.8264462809917356,\n",
       "   1.0: 0.15702479338842976,\n",
       "   2.0: 0.01652892561983471},\n",
       "  (1.0,): {0.0: 0.19298245614035087,\n",
       "   1.0: 0.6578947368421053,\n",
       "   2.0: 0.14912280701754385},\n",
       "  (2.0,): {2.0: 0.7807017543859649, 1.0: 0.21929824561403508}},\n",
       " 'cpt_smoothness': {(0.0,): {1.0: 0.2809917355371901,\n",
       "   0.0: 0.5867768595041323,\n",
       "   2.0: 0.1322314049586777},\n",
       "  (1.0,): {0.0: 0.35964912280701755,\n",
       "   1.0: 0.38596491228070173,\n",
       "   2.0: 0.2543859649122807},\n",
       "  (2.0,): {2.0: 0.5478260869565217,\n",
       "   1.0: 0.3652173913043478,\n",
       "   0.0: 0.08695652173913043}},\n",
       " 'cpt_symmetry': {(0.0,): {2.0: 0.14634146341463414,\n",
       "   0.0: 0.5609756097560976,\n",
       "   1.0: 0.2926829268292683},\n",
       "  (1.0,): {1.0: 0.453781512605042,\n",
       "   0.0: 0.31092436974789917,\n",
       "   2.0: 0.23529411764705882},\n",
       "  (2.0,): {2.0: 0.6574074074074074,\n",
       "   0.0: 0.06481481481481481,\n",
       "   1.0: 0.2777777777777778}},\n",
       " 'cpt_fractal': {(0.0,): {0.0: 0.5221238938053098,\n",
       "   1.0: 0.26548672566371684,\n",
       "   2.0: 0.21238938053097345},\n",
       "  (1.0,): {1.0: 0.3333333333333333,\n",
       "   0.0: 0.43333333333333335,\n",
       "   2.0: 0.23333333333333334},\n",
       "  (2.0,): {2.0: 0.5128205128205128,\n",
       "   1.0: 0.3504273504273504,\n",
       "   0.0: 0.13675213675213677}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1bfcb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpts_to_json(cpts):\n",
    "    serializable_cpts = {}\n",
    "    for var, cpt in cpts.items():\n",
    "        serializable_cpts[var] = {\n",
    "            str(parent_comb): {str(k): v for k, v in target_probs.items()}\n",
    "            for parent_comb, target_probs in cpt.items()\n",
    "        }\n",
    "    return serializable_cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a581bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CPTs to a JSON file\n",
    "cpt_json = cpts_to_json(cpts)\n",
    "with open(\"cancer_cpts.json\", \"w\") as f:\n",
    "    json.dump(cpt_json, f, indent=4)\n",
    "print(\"CPTs saved successfully to covid_cpts.json!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa4c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
